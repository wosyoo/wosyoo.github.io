<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Guagua’s Notion 主页</title>
        <link>https://wosyoo.github.io/</link>
        <description>一个NotionNext搭建的博客</description>
        <lastBuildDate>Sun, 06 Oct 2024 02:14:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en-US</language>
        <copyright>All rights reserved 2024, 学习小呆呱</copyright>
        <item>
            <title><![CDATA[CosyVoice]]></title>
            <link>https://wosyoo.github.io/technology/cosyvoice</link>
            <guid>https://wosyoo.github.io/technology/cosyvoice</guid>
            <pubDate>Tue, 24 Sep 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-10b0c0b4c9ec80359b3ac0252b0c56de"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-ffe7a9de5b7c412d8711311fbacea28d" data-id="ffe7a9de5b7c412d8711311fbacea28d"><span><div id="ffe7a9de5b7c412d8711311fbacea28d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#ffe7a9de5b7c412d8711311fbacea28d" title="📝 CosyVoice"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">📝 CosyVoice</span></span></h2><blockquote class="notion-quote notion-block-10b0c0b4c9ec806aa527eb8e7f7bce39"><div>一种基于监督语义令牌的可扩展多语言零样本TTS模型</div></blockquote><div class="notion-text notion-block-10b0c0b4c9ec800388e3d2546d6c6d5d">作者单位：Alibaba Speech Lab</div><div class="notion-text notion-block-1100c0b4c9ec80518413de0ba377b459">Demo: <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://fun-audio-llm.github.io/">https://fun-audio-llm.github.io/</a></div><div class="notion-text notion-block-1100c0b4c9ec8079addecc38b214f198">Code: <a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://github.com/FunAudioLLM/CosyVoice">https://github.com/FunAudioLLM/CosyVoice</a></div><div class="notion-table-of-contents notion-gray notion-block-1110c0b4c9ec80989e4ec47fbc4454b0"><a href="#ffe7a9de5b7c412d8711311fbacea28d" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">📝 CosyVoice</span></a><a href="#10b0c0b4c9ec80a9b431e681f007845a" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">论文阅读</span></a><a href="#10b0c0b4c9ec80b7b3a2c4462f7c6a79" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">1.Abstract</span></a><a href="#10b0c0b4c9ec80cea22ae661a70eefc8" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">2.Introduction</span></a><a href="#46bee8c7febe44769fa8e17eb4ab6ca6" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">3.Method</span></a><a href="#1100c0b4c9ec8061a8b3f9bed858feb0" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">4.数据集</span></a><a href="#1100c0b4c9ec80af9eb9d2dbdc958dec" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">5.实验设置</span></a><a href="#1110c0b4c9ec80b1a598f8f233c5a331" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">6.实验结果</span></a><a href="#1110c0b4c9ec8032945ad2a6f9922486" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">6.结论</span></a><a href="#81e2e65388fb4fb2a1bb1b12b2d6b58a" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">🤗 总结归纳</span></a><a href="#937f57499485462db659291f119d6614" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">📎 参考文章</span></a></div><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-10b0c0b4c9ec80a9b431e681f007845a" data-id="10b0c0b4c9ec80a9b431e681f007845a"><span><div id="10b0c0b4c9ec80a9b431e681f007845a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80a9b431e681f007845a" title="论文阅读"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">论文阅读</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-10b0c0b4c9ec80b7b3a2c4462f7c6a79" data-id="10b0c0b4c9ec80b7b3a2c4462f7c6a79"><span><div id="10b0c0b4c9ec80b7b3a2c4462f7c6a79" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80b7b3a2c4462f7c6a79" title="1.Abstract"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">1.Abstract</span></span></h4><div class="notion-text notion-block-10b0c0b4c9ec80c2b2ece1b97378bbdf">最近LLM-Based TTS以其高自然度和zero-shot能力成为语音合成模型的主流。</div><div class="notion-text notion-block-10b0c0b4c9ec805cba6be65c7d8106b1">在这种TTS范式中，语音信号会被离散成tokens序列，并以文本作为prompt进行合成。所以这种tokens序列的建模非常重要。当前的tokens提取一般是无监督的方式学习的，缺乏明确的语义信息和与文本的对齐。本文希望通过有监督的tokens来建模语音，tokens来自多语言语音识别模型，通过在编码器中插入矢量量化来获得。基于这些有监督tokens，文章提出了一个用于语音生成的基于编解码器的合成器CosyVoice，它由一个用于文本到tokens的LLM和一个用于tokens到语音的条件流匹配模型组成。实验结果表明，zero-shot语音克隆中，有监督语义标记在内容一致性和说话人相似度方面明显优于现有的无监督语义标记。此外，文章发现利用大规模数据进一步提高了合成性能，表明了CosyVoice的可扩展能力。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-10b0c0b4c9ec80cea22ae661a70eefc8" data-id="10b0c0b4c9ec80cea22ae661a70eefc8"><span><div id="10b0c0b4c9ec80cea22ae661a70eefc8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80cea22ae661a70eefc8" title="2.Introduction"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">2.Introduction</span></span></h4><div class="notion-text notion-block-10b0c0b4c9ec80bc88cee1da71bc7872">本文的创新点总结：</div><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec808da164fa2ae6effff2"><li>第一个将有监督的tokens集成到TTS当中；</li></ul><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec8001a361f700ca2da9a3"><li>通过text-to-tokens的LLM和tokens-to-speech的条件流匹配两个模块，无需额外的音素提取器和文本-音频强制对齐器；</li></ul><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec80bca9e7f50239c1f67e"><li>将x-vectors纳入LLM，把语音分解为语义、说话人和韵律。LLM对语义内容和韵律进行建模，而条件流匹配模型捕获音色和环境信息。</li></ul><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-46bee8c7febe44769fa8e17eb4ab6ca6" data-id="46bee8c7febe44769fa8e17eb4ab6ca6"><span><div id="46bee8c7febe44769fa8e17eb4ab6ca6" class="notion-header-anchor"></div><a class="notion-hash-link" href="#46bee8c7febe44769fa8e17eb4ab6ca6" title="3.Method"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">3.Method</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-10b0c0b4c9ec8083a996eab8e8e2a95a"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fd459e854-7813-4d92-9421-b7536b5eded8%2Fimage.png?table=block&amp;id=10b0c0b4-c9ec-8083-a996-eab8e8e2a95a&amp;t=10b0c0b4-c9ec-8083-a996-eab8e8e2a95a&amp;width=707.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-10b0c0b4c9ec8081b23bff2d5b1613e7">3.1 自监督tokens</div><div class="notion-text notion-block-10b0c0b4c9ec800b81b5f19448ad9e87">在CosyVoice中，采用监督的ASR模型推导出语音的监督语义语音(supervised semantic speech, S3)分词器。该模型是专有的SenseVoice ASR模型的微调版本。它经过多语种音频数据训练，具有丰富的音频内容理解能力。与原来的ASR模型不同，我们将编码器分成两部分，并在两部分之间插入矢量量化层。给定Mel谱图X作为输入，它经过位置编码和Encoder1以获得上下文感知表示H:</div><div class="notion-text notion-block-1100c0b4c9ec80058e44e7ff131ee5a6">然后，使用矢量量化器(VQ)来获得离散tokens。对于帧<!-- -->的隐藏表示<!-- -->，将码本C中最近嵌入的索引作为该时间步长的语音令牌<!-- -->:</div><div class="notion-text notion-block-1100c0b4c9ec80319c89e7c49b88e5bd">其中<!-- -->表示L2范数。在训练阶段，码本嵌入通过指数移动平均线(EMA)进行更新:</div><div class="notion-text notion-block-1100c0b4c9ec8069a3b8dbd449dcf0b3">其中α是一个预定义的衰减系数。将相应的语音标记码本嵌入作为量化隐藏表示<!-- -->，并通过剩余的编码器层Encoder2:</div><div class="notion-text notion-block-1100c0b4c9ec80b19d84c073b0728be7">注意，在剩余的编码器层之前，我们添加了一个额外的位置编码来增强时间信息。在Encoder2之后是基于transformer的ASR解码器，预测文本标签的后验概率:</div><div class="notion-text notion-block-1100c0b4c9ec80c188b6d139f8d93f39">其中<!-- -->表示teacher-forcing训练方案中左移的文本标签。</div><div class="notion-text notion-block-1100c0b4c9ec80da80a3f5a482d23feb">也就是说，模型在训练时会使用已知的正确标签序列的前 Z−1 个元素来预测第 Z 个元素。</div><div class="notion-text notion-block-1100c0b4c9ec80d3b371c9400687fb8e"><span class="notion-teal_background"><b>教师强制训练</b></span><span class="notion-teal_background">：这种训练方法是指在训练过程中，模型会使用真实的标签（而不是先前时间步的预测输出）作为当前时间步的输入，这样可以让训练更加稳定。</span></div><div class="notion-text notion-block-1100c0b4c9ec805bbb5fcfe6c416ee92">3.2 LLM for TTS</div><div class="notion-text notion-block-1100c0b4c9ec80d09601f2a624ab8057">在本节中，我们将TTS任务表述为具有大型语言模型(LLM)的自回归语音tokens生成问题。对于LLM来说，序列构建是最重要的，序列构建如下:</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1100c0b4c9ec808ebd83cdd142e632a2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:336px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Ff04160a0-b668-4f24-833b-a0d0be9751df%2Fimage.png?table=block&amp;id=1100c0b4-c9ec-808e-bd83-cdd142e632a2&amp;t=1100c0b4-c9ec-808e-bd83-cdd142e632a2&amp;width=336&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1100c0b4c9ec8043af93e601324f5fc8">S和E分别表示序列的开始和结束。v是使用预训练的声纹模型从语音X中提取的说话人嵌入向量。文本编码<!-- -->是通过将文本传递给字节对编码(Byte Pair Encoded, BPE)标记器和文本编码器获得的:</div><div class="notion-text notion-block-1100c0b4c9ec803db38ac250136f784c">由于文本和语音标记位于不同的语义层次，文本编码器用于对齐它们的语义空间，并有利于LLM建模。在文本编码和语音标记<!-- -->之间插入一个开始标识符 <b>T</b>，语音标记是用3.1中描述的监督语义标记器提取的。在训练阶段，我们采用teacher-forcing方案，其中左移序列作为模式输入，原始序列作为期望输出。注意，在训练过程中只考虑语音tokens和 <b>E</b> 的交叉熵损失:</div><div class="notion-text notion-block-1100c0b4c9ec80ef9ce8f06778217ed2">其中<!-- -->为“序列结束”标记 <b>E</b>。<!-- -->为<!-- -->的后验概率，由LLM之后的softmax层预测。</div><div class="notion-text notion-block-1100c0b4c9ec8026af46f69e6d799d97">3.3 最优传输条件流匹配 Optimal-transport Conditional Flow Matching</div><div class="notion-text notion-block-1100c0b4c9ec8084a12df0e37d914e73">在CosyVoice中，采用最优传输条件流匹配模型(OT-CFM)学习Mel谱图的分布，并以生成的语音tokens为条件生成样本。与梯度更简单、训练更容易、生成更快的扩散概率模型(dpm)相比，OT-CFM可以获得更好的性能(文章给出了参考文献)。在连续时间归一化流(continuous-time normalizing flows, CNFs)中，从先验分布<!-- -->到Mel谱图数据分布<!-- -->构建了概率密度路径。</div><div class="notion-text notion-block-1100c0b4c9ec80f3bcbef2fe93724b2e">概率密度路径由与时间相关的向量场<!-- -->定义:<!-- -->，通过常微分方程(ODE)得到流<!-- -->:</div><div class="notion-text notion-block-1100c0b4c9ec80e2a389c2bf7beb91f7">其中<!-- -->.通过求解初值问题，我们可以用<!-- -->近似语音分布<!-- -->并从中采样。为了学习向量场<!-- -->，我们定义了最优传输(OT)流，并强制神经网络通过最小化以下损失来匹配它:</div><div class="notion-text notion-block-1100c0b4c9ec80f59334f2cf1803e5bc">其中</div><div class="notion-text notion-block-1100c0b4c9ec80a3982fc7b4b4e43ead">将嵌入的说话人v、语音令牌<!-- -->和masked Mel谱图<!-- -->输入神经网络，用可学习参数θ匹配向量场:</div><div class="notion-text notion-block-1100c0b4c9ec80828f56c693cfb0952a">通过将从随机起始点到结束点的连续帧设置为零，<!-- -->是<!-- -->的掩码版本。考虑到一开始的生成过程比后面的更难，我们在时间步长t上加入了一个余弦调度器:</div><div class="notion-text notion-block-1100c0b4c9ec804aabf9f129b90e3a3c">调度器后的flow的初始生成步骤会变多。</div><div class="notion-text notion-block-1100c0b4c9ec8043a9d0fc178b95a15e">无分类器制导(Classifier-free guidance, CFG)已被证明可以提高扩散概率模型的生成质量(参考文献)。因此，我们建议将CFG应用到条件流匹配模型中。在训练阶段，我们随机丢弃条件<!-- -->，固定概率为0.2。用这种方式，条件和非条件的flow我们都能学到。</div><div class="notion-text notion-block-1100c0b4c9ec80688af7cd9ecab30844">在生成过程中，向量场修改如下:</div><div class="notion-text notion-block-1100c0b4c9ec806fbd63c7a3c4557bb2">其中β为0.7的引导强度。</div><div class="notion-text notion-block-1100c0b4c9ec809db7a5d3b93ef58dae">3.3.1 零样本情境学习 Zero-shot In-context Learning</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1100c0b4c9ec8035b062ff41a7de9c57"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F21d735ef-fff5-4522-a052-954ece4e6e54%2Fimage.png?table=block&amp;id=1100c0b4-c9ec-8035-b062-ff41a7de9c57&amp;t=1100c0b4-c9ec-8035-b062-ff41a7de9c57&amp;width=432&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1100c0b4c9ec80e1916ee7f02ca6de61">CosyVoice模型展示了零样本上下文学习能力，允许只使用简短的参考语音样本复制任意语音。这个过程需要仔细构建token语言模型(LM)的输入序列，如图2所示。对于同一语言的提示语音和输入文本，我们将它们合并以形成统一的输入，将提示语音标记视为预先生成的。使用这个输入序列，自回归LM迭代地预测后续tokens，直到遇到“序列结束”标记 <b>E</b>。然而，当提示语和输入文本在语言上不同时，我们省略了与提示语相关的文本和tokens，以防止原语的韵律特征影响目的语。值得注意的是，与提示语音内容相对应的提示文本可以通过人工注释或ASR模型(如SenseVoice)进行转录。与提示文本类似，使用S3标记器从提示语音中提取提示标记。</div><div class="notion-text notion-block-1100c0b4c9ec80caaf92fe3c3c262e5d">生成语音tokens后，将其附加在提示tokens之后，形成流匹配模型的复合条件。此外，还结合了说话人嵌入和提示语音的Mel谱图，进一步增强了音色和环境一致性。</div><div class="notion-text notion-block-1100c0b4c9ec805797d2f710fb4cc100">3.4 利用指令进行丰富多样的生成 Rich Generation with Instruction</div><div class="notion-text notion-block-1100c0b4c9ec8087a138c5a9c412b470">为了在CosyVoice上实现进一步的可控性，我们尝试集成额外的指令微调。CosyVoice-instruct扩展了CosyVoice-base，增强了指令跟随功能。具体来说，它支持各种方面的可控性，如说话者身份(即说话者的特征)、说话风格(包括情感、性别、语速和音高)和细粒度的副语言特征。这些功能包括插入笑声、呼吸、边笑边说话以及强调某些单词的能力。我们使用这些训练数据对CosyVoice-base进行了微调，但没有将说话人嵌入到自回归语言模型中。表1显示了说话者身份、说话风格和细粒度副语言特征的一些示例。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1100c0b4c9ec805ab27ee6b535aeec5e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F1c7fe857-b255-4fc7-93a0-a26996a5cfa2%2Fimage.png?table=block&amp;id=1100c0b4-c9ec-805a-b27e-e6b535aeec5e&amp;t=1100c0b4-c9ec-805a-b27e-e6b535aeec5e&amp;width=707.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1100c0b4c9ec8003a260efaacff0a8bf">Github有一些instruct 的demo展示。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-1100c0b4c9ec8061a8b3f9bed858feb0" data-id="1100c0b4c9ec8061a8b3f9bed858feb0"><span><div id="1100c0b4c9ec8061a8b3f9bed858feb0" class="notion-header-anchor"></div><a class="notion-hash-link" href="#1100c0b4c9ec8061a8b3f9bed858feb0" title="4.数据集"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">4.数据集</span></span></h4><div class="notion-text notion-block-1100c0b4c9ec8077a304feef0485bb87"><b>4.1 小规模单一语种数据集</b></div><div class="notion-text notion-block-1100c0b4c9ec803e888dd10e81f8619e">我们在LibriTTS语料库上进行了实验，该语料库包含来自2,456名英语使用者的585个小时。我们遵循官方数据分区，其中“train-clean-100”，“trainclean-360”和“train-other-500”被合并用于训练，“dev-clean”用于模型选择。使用“test-clean”构建评估集。</div><div class="notion-text notion-block-1100c0b4c9ec809aa351d85cc47201b7"><b>4.2 大规模多语种数据集</b></div><div class="notion-text notion-block-1100c0b4c9ec803fa93bc605f80a6b56">为了训练CosyVoice模型，我们已经积累了包含多种语言的大量数据集。在整个收集过程中，我们利用专门的内部工具进行语音检测，信噪比(SNR)估计，说话人分离。</div><div class="notion-text notion-block-1100c0b4c9ec80f198dddc740de7a4a3">然后利用SenseVoice和Paraformer来对语音进行转录得到文本标签。这些标签在Force-Alignment(FA)模型的帮助下经过改进，有助于消除低质量数据并提高标点符号的准确性。表2列出了跨各种语言的训练数据持续时间的全面细分。表3给出了不同类型指令的训练数据持续时间。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1100c0b4c9ec806d9af2eb9e84354292"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:384px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fe4d819aa-8cba-4733-a682-dfc817b4aa8c%2Fimage.png?table=block&amp;id=1100c0b4-c9ec-806d-9af2-eb9e84354292&amp;t=1100c0b4-c9ec-806d-9af2-eb9e84354292&amp;width=384&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1100c0b4c9ec805881d2fad53e1111e2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:384px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fd136b2bb-0c0e-46b6-bc09-65f2dcd25a65%2Fimage.png?table=block&amp;id=1100c0b4-c9ec-8058-81d2-fad53e1111e2&amp;t=1100c0b4-c9ec-8058-81d2-fad53e1111e2&amp;width=384&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-1100c0b4c9ec80af9eb9d2dbdc958dec" data-id="1100c0b4c9ec80af9eb9d2dbdc958dec"><span><div id="1100c0b4c9ec80af9eb9d2dbdc958dec" class="notion-header-anchor"></div><a class="notion-hash-link" href="#1100c0b4c9ec80af9eb9d2dbdc958dec" title="5.实验设置"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">5.实验设置</span></span></h4><div class="notion-text notion-block-1110c0b4c9ec80ca838bee307ecdca76">5.1 监督的语义分词器</div><div class="notion-text notion-block-1110c0b4c9ec801b82e8c42c49d6c66f">对于小规模单语言数据集，我们采用ESPNet Conformer ASR模型作为主干，并在前六层编码器层之后插入矢量量化器。一个码本有4096个码字。采用前六层编码器层和矢量量化器作为语音分词器。对于文本分词器，使用训练文本训练了一个词级的sentence-piece模型，该模型的词汇量为4,000。我们在librisspeech 语料库上从零开始训练了50个epoch的量化增强ASR模型。</div><div class="notion-text notion-block-1110c0b4c9ec809b891fc6a6b59cac9d">对于大规模的多语言数据集，我们采用SenseVoice-Large富识别模型作为主干。与小规模数据集类似，我们仍然在前六个编码器层之后插入矢量量化器，并使用单个4096个码字的码本。更多的超参数选择，如量化器插入层和代码数量，将留给未来的工作。与单语言实验不同，我们使用预训练的检查点来初始化sensevoicellarge模型，而不是从头开始训练它。在插入量化器后，我们在八个A800 GPU上对全部参数进行了进一步微调，共进行了210,000个训练步骤。</div><div class="notion-text notion-block-1110c0b4c9ec80bcb281e30fa1b23ef9">5.2 CosyVoice模型设置</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec80efa292e83d73abb646"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:336px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F0b340064-c645-4d4b-9112-7de1ae25a850%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-80ef-a292-e83d73abb646&amp;t=1110c0b4-c9ec-80ef-a292-e83d73abb646&amp;width=336&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1110c0b4c9ec80e89eb5e31370d60252">我们在单语和多语实验中训练了小型和常规尺寸的模型。模型架构设置的详细信息如表4所示。小型模型在LibriTTS训练集上使用四个V100-32M GPU进行了50个epoch的训练，而多语模型在我们内部数据集上使用64个V100-32M GPU进行了800,000步的训练。小型和常规模型的学习率分别为10⁻³和10⁻⁴，预热步骤设为10,000。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-1110c0b4c9ec80b1a598f8f233c5a331" data-id="1110c0b4c9ec80b1a598f8f233c5a331"><span><div id="1110c0b4c9ec80b1a598f8f233c5a331" class="notion-header-anchor"></div><a class="notion-hash-link" href="#1110c0b4c9ec80b1a598f8f233c5a331" title="6.实验结果"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">6.实验结果</span></span></h4><div class="notion-text notion-block-1110c0b4c9ec809db32dca171730610c">6.1 对于监督语义分词器的评价</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec808cbb07c7bb216e731e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:384px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F50bbd350-1b52-4ebf-8d0d-a05ca9b09053%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-808c-bb07-c7bb216e731e&amp;t=1110c0b4-c9ec-808c-bb07-c7bb216e731e&amp;width=384&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1110c0b4c9ec80bca01ec4bd983db50c">在表5中，我们演示了矢量量化如何影响LibriSpeech测试集上的识别性能。从表中可以看出，在ASR编码器中插入矢量量化器对识别性能的影响很小。结果表明，插入vq的Conformer ASR模型在“test-clean”集和“test-other”集上的wer分别达到了3.18%和7.56%。这表明以监督方式训练的标记器可以保持足够的语义信息和与文本的对齐。</div><div class="notion-text notion-block-1100c0b4c9ec804baad5e995b9e279df">为了评估多语种S³分词器在保留语义信息方面的能力，我们将量化增强的SenseVoice-L与其原始版本以及Whisper-Large V3模型的识别性能进行了比较。模型使用Common Voice zh-CN和en基准进行了评估，结果详见表6。从表中可以看出，我们的S³分词器在中文和英文测试集上表现出了稳健的识别性能。特别是在common_voice_zh-CN数据集上，S³分词器的表现超过了Whisper-Large V3模型，错误率相对降低了4.14%。这表明S³分词器与语义内容之间存在显著的相关性。值得注意的是，S³分词器中仅有一个码本，且其词典规模为4,096个条目。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec80999d6ec1b6c69d6d92"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F4371dee7-48a7-4874-8f35-d08ffda7bf60%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-8099-9d6e-c1b6c69d6d92&amp;t=1110c0b4-c9ec-8099-9d6e-c1b6c69d6d92&amp;width=432&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1100c0b4c9ec8009bdf0db79683553ad">6.2 与基线模型相比较</div><div class="notion-text notion-block-1110c0b4c9ec80d9ae99f6f6c4c9760c">我们将所提出的CosyVoice模型与其他TTS系统在内容一致性和说话人相似性方面进行了比较。为了保证内容的一致性，采用ASR模型对生成的话语进行识别。我们报告了词错误率（WER），以及插入、删除和替换错误的数量。在说话人相似度方面，我们采用ERes2Net模型提取提示话语和生成话语的说话人嵌入，并将其原始余弦相似度作为说话人相似度。实验结果如表7所示。</div><div class="notion-text notion-block-1110c0b4c9ec80d6a849edeb3d28b7b7">与其他TTS模型相比，所提出的CosyVoice框架即使使用相同的文本和语音分词器，也能够实现可比的内容一致性和更高的说话者相似性。通过对比Exp-1、Exp-2和Exp-3，可以看出文本和语音分词器对内容一致性至关重要，而对说话者相似性的影响可以忽略不计。在Exp-4实验中，我们将单语的文本和语音分词器替换为多语的分词器。仅使用LibriTTS语料库训练模型会导致内容一致性和说话者相似性下降。而通过引入内部的大规模数据集，性能得到显著提升，达到了与人类相当的质量。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec8040ae8edb6a3d78f8e1"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F88caa6a0-1e80-4850-90b4-11b72d63d243%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-8040-ae8e-db6a3d78f8e1&amp;t=1110c0b4-c9ec-8040-ae8e-db6a3d78f8e1&amp;width=707.9765625&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1100c0b4c9ec8041881bc3b6eb09a4bf">6.3 CosyVoice生成质量的评价</div><div class="notion-text notion-block-1110c0b4c9ec80b6baa8ee27c52c5358">我们通过检查内容一致性和说话人相似性来评估CosyVoice的语音合成质量。使用LibriTTS的“test-clean”子集和AISHELL-3的测试集分别构建英语和汉语的评估集。对于这些集合中的每个文本，我们随机选择一个提示语音。使用Whisper-Large V3评估英语的内容一致性，使用Paraformer 评估中文识别的内容一致性。通过计算使用ERes2Net提取的生成和提示语音的说话人嵌入之间的余弦相似度来量化说话人相似度。</div><div class="notion-text notion-block-1110c0b4c9ec80a8b64bd8634a904fbc">与其他自回归语言模型类似，我们对我们的标记语言模型采用了随机采样解码策略，并使用五个不同的随机种子值（0、7、42、123和1,337）来评估合成过程。结果评估指标取平均值和标准差。此外，我们还进行了自动语音识别（ASR）重新排序Reranking，以展示离线模式下潜在的性能改进。</div><blockquote class="notion-quote notion-block-1110c0b4c9ec80cd8aaeef0acabd2d22"><div><b>什么是ASR Reranking？</b>
ASR-Reranking（自动语音识别重排序）用于提高 ASR系统的输出质量。在ASR过程中，系统通常会根据语音信号生成多个候选文本序列（这些序列通常由声学模型和语言模型联合计算），然后通过不同的方法对这些候选序列进行评分和排序，最后选择最优的输出文本。ASR-Reranking就是在这个步骤中重新调整这些候选文本的顺序，以期提高识别的准确性。
假设一个ASR系统在识别&quot;Can you <b>send</b> me a message&quot;时生成了多个候选输出，包括“send”和“sand”。通过引入Reranking，系统可以利用语境信息判断“send”在这个句子中更符合语法和上下文，从而优先选择它作为最终输出。</div></blockquote><div class="notion-text notion-block-1110c0b4c9ec8079896ef0dc78e666b7">表8和表9分别给出了英文和中文的结果。在英语数据集上，CosyVoice达到了人类水平的性能，具有相似的内容识别和更高的说话人相似度。ASR重新排序显著增强了内容一致性，单词错误率(WER)降低到1.51%。CosyVoice在WER和插入和删除错误数量上都优于ChatTTS，表明其内容一致性更好。我们没有评估ChatTTS的说话者相似度，因为它没有释放语音克隆功能。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec80d5b609d0a6fd13ce94"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:384px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F6696ae93-ce33-471e-8bde-94e3689f49c5%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-80d5-b609-d0a6fd13ce94&amp;t=1110c0b4-c9ec-80d5-b609-d0a6fd13ce94&amp;width=384&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1110c0b4c9ec8042952af2863b746ad9">对于汉语的结果，CosyVoice生成的话语与原始话语相比，在CER和插入、删除的错误上都达到了相当的水平。在字符错误率（CER）方面，ChatTTS在中文生成能力上似乎优于英文。尽管ChatTTS和CosyVoice达到了相似的CER，但ChatTTS产生了更多的插入和删除错误。这是由于说话者泄漏问题导致的，即意外生成了另一位说话者的语气词。相反，CosyVoice没有遇到这个问题，其插入和删除错误要少得多。通过自动语音识别（ASR）重新排序，CosyVoice达到了非常低的1.84%的CER。正如在英文中所见，CosyVoice在说话者相似性方面也超过了原始语音，展示了其有效的声音克隆能力。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec806994e0eaa07fd44af4"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fcea68128-3cb4-4a69-921e-91c9437fffa9%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-8069-94e0-eaa07fd44af4&amp;t=1110c0b4-c9ec-8069-94e0-eaa07fd44af4&amp;width=432&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1110c0b4c9ec806ebaefebd424cb8695">6.4 CosyVoice的情绪可控性</div><div class="notion-text notion-block-1110c0b4c9ec80ffba01d495656674c4">为了验证情绪的可控制性，我们使用了公共演讲情绪识别模型emo2vec3 (Ma et al.， 2023)。我们为六种情绪中的每一种生成并评估了100个英语表达:快乐、愤怒、悲伤、惊讶、恐惧和厌恶。合成文本的内容被设计成与目标情感相匹配。然后，我们测量从合成语音中预测每种情绪的准确性。</div><div class="notion-text notion-block-1110c0b4c9ec801abd4fca92a78dbe2d">表10显示了CosyVoice-base和cosyvoice - directive的情绪控制准确率比较。对于CosyVoice-instruct，输入由内容文本和说话风格指令组成(例如，“Happy”。&lt; endofprompt &gt;内容文本”)。相比之下，CosyVoice-base只接收内容文本作为输入。结果表明，带有情感指令的CosyVoice-instruct比不带情感指令的CosyVoice-instruct和CosyVoice -base都有显著的提高。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec80f88954f036308c964e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F4ae1df1e-8d64-4e91-a0f2-3ff27c74cb84%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-80f8-8954-f036308c964e&amp;t=1110c0b4-c9ec-80f8-8954-f036308c964e&amp;width=707.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-1110c0b4c9ec80f6b1e1d36571b11d7f">6.5 CosyVoice作为数据生成器</div><div class="notion-text notion-block-1110c0b4c9ec803ca616c92f6459cf21">CosyVoice 的一个直接应用是作为数据生成器，用于增强其他任务的训练数据，例如自动语音识别（ASR）和语音到语音翻译（S2ST）。以ASR任务为例，我们在Librispeech语料库上进行了实验，以评估CosyVoice在生成高质量数据方面的能力。实验结果如表11所示，其中“Librispeech”表示原始的960小时数据。“Syn on LS text”和“Syn on MLS text”分别表示使用Librispeech和MLS训练集文本生成的数据。从表中可以看出，ASR模型仅在合成数据上训练时，能够达到与原始Librispeech训练集相当的结果。通过将二者结合，识别准确率显著提高。一个有趣的发现是，使用MLS文本生成的合成数据显著提升了识别性能。这可能表明，对于ASR任务而言，文本的多样性比语音时长更为重要。这一改进可归因于CosyVoice生成样本所引入的丰富语言内容。我们的评估结果强调了CosyVoice生成样本的高质量。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-1110c0b4c9ec806aa009fc9d0a74c70a"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fdc07a4bd-bd4a-4b41-8914-753c6a496493%2Fimage.png?table=block&amp;id=1110c0b4-c9ec-806a-a009-fc9d0a74c70a&amp;t=1110c0b4-c9ec-806a-a009-fc9d0a74c70a&amp;width=707.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-1110c0b4c9ec8032945ad2a6f9922486" data-id="1110c0b4c9ec8032945ad2a6f9922486"><span><div id="1110c0b4c9ec8032945ad2a6f9922486" class="notion-header-anchor"></div><a class="notion-hash-link" href="#1110c0b4c9ec8032945ad2a6f9922486" title="6.结论"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">6.结论</span></span></h4><div class="notion-text notion-block-1110c0b4c9ec8014b21cf5fec2418e45">在本文中，我们介绍了CosyVoice，一种可扩展的多语言语音生成模型，支持零样本的上下文学习、跨语言的声音克隆、指令生成以及情感和副语言特征的细粒度控制。实验结果表明，CosyVoice的系统架构对于说话者相似性至关重要，而文本和语音分词器则对内容一致性有较大影响。此外，我们发现扩展模型规模和数据量可以显著提高性能。因此，CosyVoice实现了与人类生成质量相当的水平。</div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-81e2e65388fb4fb2a1bb1b12b2d6b58a" data-id="81e2e65388fb4fb2a1bb1b12b2d6b58a"><span><div id="81e2e65388fb4fb2a1bb1b12b2d6b58a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#81e2e65388fb4fb2a1bb1b12b2d6b58a" title="🤗 总结归纳"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">🤗 总结归纳</span></span></h2><div class="notion-text notion-block-1110c0b4c9ec80dda0b1d3299d4fce65">Generated By NotionAI</div><div class="notion-text notion-block-1110c0b4c9ec80dbbfcffc7d90c8c9fb"><b>概述</b></div><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec800b9a8debd26556dfa0"><li>CosyVoice是一种基于监督语义令牌的可扩展多语言零样本TTS模型，由Alibaba Speech Lab开发</li></ul><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec8041a04ff673307fb865"><li>模型由文本到令牌的LLM和令牌到语音的条件流匹配模型组成，实现了零样本语音克隆</li></ul><div class="notion-text notion-block-1110c0b4c9ec800f9dfeca7c3cd5ce60"><b>创新点</b></div><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec8018be63e8213b48b01f"><li>首次将有监督的语音令牌集成到TTS中，提高了内容一致性和说话人相似度</li></ul><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec806faa63e7c483ec4146"><li>无需额外的音素提取器和文本-音频强制对齐器</li></ul><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec80e188ffc03110471ca3"><li>将x-vectors纳入LLM，实现语音的语义、说话人和韵律分解</li></ul><div class="notion-text notion-block-1110c0b4c9ec80f598b8fc7613b74400"><b>性能与应用</b></div><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec80efbc58c498b7072595"><li>在英语和中文数据集上达到了与人类相当的性能，在内容一致性和说话人相似度方面表现优异</li></ul><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec806495dcc7510076f31a"><li>支持情感和副语言特征的细粒度控制，展示了良好的情绪可控性</li></ul><ul class="notion-list notion-list-disc notion-block-1110c0b4c9ec80bcb5f7e945c1631ff5"><li>可作为高质量数据生成器，用于增强ASR和语音到语音翻译等任务的训练数据</li></ul><div class="notion-blank notion-block-1110c0b4c9ec8054a783cff4520be879"> </div><div class="notion-blank notion-block-1110c0b4c9ec8091b4d6ea203cb7751b"> </div><div class="notion-blank notion-block-1110c0b4c9ec8039a2bdedd07d96e5d0"> </div><div class="notion-blank notion-block-1110c0b4c9ec80e28819f4120c874fd2"> </div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-937f57499485462db659291f119d6614" data-id="937f57499485462db659291f119d6614"><span><div id="937f57499485462db659291f119d6614" class="notion-header-anchor"></div><a class="notion-hash-link" href="#937f57499485462db659291f119d6614" title="📎 参考文章"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">📎 参考文章</span></span></h2><ul class="notion-list notion-list-disc notion-block-8d2d21d29d31425a96e3a7d6ca9ef29f"><li>一些引用</li></ul><ul class="notion-list notion-list-disc notion-block-8b492ecc89b944bb97cf9281576afcfa"><li>引用文章</li></ul><div class="notion-blank notion-block-ac549f1424a44709b92881cc9a60c210"> </div><div class="notion-blank notion-block-1110c0b4c9ec806b8648c191502deeb1"> </div></main></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Flow-based Generative model]]></title>
            <link>https://wosyoo.github.io/technology/flow</link>
            <guid>https://wosyoo.github.io/technology/flow</guid>
            <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec8197b935f4879f5122b3"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-text notion-block-fff0c0b4c9ec810db31be874a6747607">资料来源：</div><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-fff0c0b4c9ec8173878df535d92a6c63" href="https://0809zheng.github.io/2022/05/01/flow.html"><div><div class="notion-bookmark-title">流模型(Flow-based Model) - 郑之杰的个人网站</div><div class="notion-bookmark-description">为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平</div><div class="notion-bookmark-link"><div class="notion-bookmark-link-icon"><img src="https://www.notion.so/image/https%3A%2F%2F0809zheng.github.io%2Ffavicon.ico?table=block&amp;id=fff0c0b4-c9ec-8173-878d-f535d92a6c63&amp;t=fff0c0b4-c9ec-8173-878d-f535d92a6c63" alt="流模型(Flow-based Model) - 郑之杰的个人网站" loading="lazy" decoding="async"/></div><div class="notion-bookmark-link-text">https://0809zheng.github.io/2022/05/01/flow.html</div></div></div></a></div><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-fff0c0b4c9ec81c5a03df2e02c0c5f5a" href="https://www.youtube.com/watch?v=uXY18nzdSsM"><div><div class="notion-bookmark-title">Flow-based  Generative Model</div><div class="notion-bookmark-link"><div class="notion-bookmark-link-icon"><img src="https://www.notion.so/image/https%3A%2F%2Fwww.youtube.com%2Fs%2Fdesktop%2F11fc5992%2Fimg%2Ffavicon_144x144.png?table=block&amp;id=fff0c0b4-c9ec-81c5-a03d-f2e02c0c5f5a&amp;t=fff0c0b4-c9ec-81c5-a03d-f2e02c0c5f5a" alt="Flow-based  Generative Model" loading="lazy" decoding="async"/></div><div class="notion-bookmark-link-text">https://www.youtube.com/watch?v=uXY18nzdSsM</div></div></div><div class="notion-bookmark-image"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fi.ytimg.com%2Fvi%2FuXY18nzdSsM%2Fhqdefault.jpg?table=block&amp;id=fff0c0b4-c9ec-81c5-a03d-f2e02c0c5f5a&amp;t=fff0c0b4-c9ec-81c5-a03d-f2e02c0c5f5a" alt="Flow-based  Generative Model" loading="lazy" decoding="async"/></div></a></div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-fff0c0b4c9ec812eb2e5e1ac5fc2909f" data-id="fff0c0b4c9ec812eb2e5e1ac5fc2909f"><span><div id="fff0c0b4c9ec812eb2e5e1ac5fc2909f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec812eb2e5e1ac5fc2909f" title="目录"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">目录</span></span></h2><div class="notion-table-of-contents notion-gray notion-block-fff0c0b4c9ec8194926fc9f45a60b794"><a href="#fff0c0b4c9ec812eb2e5e1ac5fc2909f" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">目录</span></a><a href="#fff0c0b4c9ec81a89ff9ff1c234590a0" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">前面生成模型存在的问题</span></a><a href="#fff0c0b4c9ec817eb9a4d40447f4e8f8" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">Generator</span></a><a href="#fff0c0b4c9ec81919d91d70bf8abb166" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">Math Background</span></a><a href="#fff0c0b4c9ec81c39397cc067dda7e58" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">Jacobian Matrix</span></a><a href="#fff0c0b4c9ec81a39f03eefb11897736" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">Determinant(行列式)</span></a><a href="#fff0c0b4c9ec811e931ec19099d0a524" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">Change of Variable Theorem(变量替换定理)</span></a><a href="#fff0c0b4c9ec816ab3afc086b1afac3b" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">Flow-based Model</span></a><a href="#fff0c0b4c9ec81a8a0e8db6fc7d48a4f" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">Coupling layer</span></a><a href="#fff0c0b4c9ec8135b1e0d554b52677cd" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:48px">Coupling layer - stacking</span></a><a href="#fff0c0b4c9ec814baabcf9d0fac22bb5" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">Glow</span></a></div><div class="notion-text notion-block-10d0c0b4c9ec803d9e93f3401c484936"><b>NotionAI总结：</b></div><div class="notion-text notion-yellow_background notion-block-10d0c0b4c9ec801ab0eff361f8f8871f"><b>Flow-based 生成模型概述</b></div><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec8094be4cda46ce842ee5"><li>Flow-based 模型是一种可以直接优化似然函数的生成模型，克服了其他生成模型的一些局限性</li></ul><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec80cdbae0ea51cfe1ca7b"><li>基于变量替换定理，Flow 模型建立了原始分布和生成分布之间的关系</li></ul><div class="notion-text notion-yellow_background notion-block-10d0c0b4c9ec80589ecccf4df9cec317"><b>模型结构与特点</b></div><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec806499c1cc2552379eb0"><li>Generator 的设计需要保证输入输出维度一致，且雅可比矩阵行列式可计算</li></ul><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec80199ee2fea258533a33"><li>Coupling layer 是一种常用的 Generator 结构，易于计算逆函数和雅可比行列式</li></ul><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec80ebb58dd1bca56c8dcc"><li>多个 Generator 的堆叠可以增强模型的表达能力</li></ul><div class="notion-text notion-yellow_background notion-block-10d0c0b4c9ec8032a403fa273e506b33"><b>Glow 模型</b></div><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec80dbac13d3e0bb8cf25e"><li>Glow 模型使用 1x1 卷积作为 Generator，可以自动学习通道间的交换</li></ul><ul class="notion-list notion-list-disc notion-block-10d0c0b4c9ec808f8ef8ca1e838c96a7"><li>1x1 卷积的核矩阵就是其雅可比矩阵，简化了计算</li></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-fff0c0b4c9ec81a89ff9ff1c234590a0" data-id="fff0c0b4c9ec81a89ff9ff1c234590a0"><span><div id="fff0c0b4c9ec81a89ff9ff1c234590a0" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81a89ff9ff1c234590a0" title="前面生成模型存在的问题"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">前面生成模型存在的问题</span></span></h3><div class="notion-text notion-block-fff0c0b4c9ec81279996d4891abe84ce">1.Auto-regressive model</div><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec8166b247df2c3d734182"><li>对于图像来说，不知道生成每个像素的顺序是什么</li></ul><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec8125b90affadf9473bc6"><li>一步一步生成，速度太慢</li></ul><div class="notion-text notion-block-fff0c0b4c9ec8177b420e7c2ec011805">2.VAE</div><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec81cf8fb5c0d6d41a9de7"><li>优化对象不是似然，而是似然的下界</li></ul><div class="notion-text notion-block-fff0c0b4c9ec81b49f24d6e85f44034e">3.GAN</div><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec813bb3a1fcee8d181e32"><li>训练不稳定/难以训练</li></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-fff0c0b4c9ec817eb9a4d40447f4e8f8" data-id="fff0c0b4c9ec817eb9a4d40447f4e8f8"><span><div id="fff0c0b4c9ec817eb9a4d40447f4e8f8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec817eb9a4d40447f4e8f8" title="Generator"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Generator</span></span></h3><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec8119bec4cc14a48ae2eb"><li>A generator G is a network. The network defines a probability distribution </li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8134af94ebb672496c9c"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6784061c-fc35-4ad0-a10d-402476e28fa0%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8134-af94-ebb672496c9c&amp;t=fff0c0b4-c9ec-8134-af94-ebb672496c9c&amp;width=707.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec811d9dcac975ed01b33d">由于G是一个network，所以<!-- -->显然非常的复杂，一般不知道怎么最大化似然函数，但是flow可以直接优化似然函数！</div><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-fff0c0b4c9ec81919d91d70bf8abb166" data-id="fff0c0b4c9ec81919d91d70bf8abb166"><span><div id="fff0c0b4c9ec81919d91d70bf8abb166" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81919d91d70bf8abb166" title="Math Background"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Math Background</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-fff0c0b4c9ec81c39397cc067dda7e58" data-id="fff0c0b4c9ec81c39397cc067dda7e58"><span><div id="fff0c0b4c9ec81c39397cc067dda7e58" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81c39397cc067dda7e58" title="Jacobian Matrix"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Jacobian Matrix</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8144adf9e3b99ba24a64"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0f3d9d6e-c691-4974-8473-61c6b739da48%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8144-adf9-e3b99ba24a64&amp;t=fff0c0b4-c9ec-8144-adf9-e3b99ba24a64&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8137bab1d4571fc04ce5">对于输入z，函数f会产生输出x。那么函数f的Jacobian Matrix就是上图的<!-- -->, 注意这个矩阵的顺序关系是不能改变的。f的反函数就是<!-- -->, 计算可以得到<!-- -->的Jacobian Matrix如图。那么有如下性质：<!-- -->(单位矩阵)</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-fff0c0b4c9ec81a39f03eefb11897736" data-id="fff0c0b4c9ec81a39f03eefb11897736"><span><div id="fff0c0b4c9ec81a39f03eefb11897736" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81a39f03eefb11897736" title="Determinant(行列式)"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Determinant(行列式)</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec818baa9cfe5d689d76ab"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1d61a3f2-14dd-4e2a-9786-63525ff135e6%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-818b-aa9c-fe5d689d76ab&amp;t=fff0c0b4-c9ec-818b-aa9c-fe5d689d76ab&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81e0b0d7cb4c74c1bf4f">|Det(A)|实际上计算的是以高维空间以方阵A每一行为坐标点围成形状的“体积”。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec818fb786ff89b45e2b5e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6190059c-1dda-485f-add1-87f05a824b91%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-818f-b786-ff89b45e2b5e&amp;t=fff0c0b4-c9ec-818f-b786-ff89b45e2b5e&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-fff0c0b4c9ec811e931ec19099d0a524" data-id="fff0c0b4c9ec811e931ec19099d0a524"><span><div id="fff0c0b4c9ec811e931ec19099d0a524" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec811e931ec19099d0a524" title="Change of Variable Theorem(变量替换定理)"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Change of Variable Theorem(变量替换定理)</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec814f82d1cae003b3fe91">如果我们有一个原始的分布π(z), 通过一个变换函数x=f(z), 得到的x任然是一个分布p(x)，那么这两个分布p(x)和π(z)有什么关系呢？</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81b18d6afa2129d60242"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa6b48429-b39b-4a00-9ae6-efa2a953fad4%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81b1-8d6a-fa2129d60242&amp;t=fff0c0b4-c9ec-81b1-8d6a-fa2129d60242&amp;width=707.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81639bd6cea478debaa9">假如z是一个01均匀分布，那么z的概率密度函数如图π(z)所示。由于密度函数积分为1，所以正方形高为1.</div><div class="notion-text notion-block-fff0c0b4c9ec81ec81e2d19fd779f5a6">x=2z+1, 那么x的密度函数取值范围就是[1,3]，那么绿色正方形高就是0.5.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81bc995dc8e600165dea"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0f4386cd-dd44-4598-ba7c-71dfd73d486b%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81bc-995d-c8e600165dea&amp;t=fff0c0b4-c9ec-81bc-995d-c8e600165dea&amp;width=707.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81419d4fe5eb1cbbf48e">那么我们推广到一般情况，我们不知道z的分布和x的分布。我们在<!-- -->到∆z之间取值，那么经过变换函数x=f(z), 这一段x的取值记为<!-- -->到∆x.</div><div class="notion-text notion-block-fff0c0b4c9ec81f99ccbfa43521fb90b">在这一部分概率密度函数应该有相同的面积，所以可以由图中公式得出结论。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8194b231e2264dab8ca0"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd2c6830a-b21b-4df8-b850-3ea052f6bec6%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8194-b231-e2264dab8ca0&amp;t=fff0c0b4-c9ec-8194-b231-e2264dab8ca0&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81039220ff8627fb8fbe">推广到二维和多维情况：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8181ab40f88381204d35"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff089bfd3-3aad-45ce-85f3-d60309720ef3%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8181-ab40-f88381204d35&amp;t=fff0c0b4-c9ec-8181-ab40-f88381204d35&amp;width=707.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec817582acfca46cda47b3">对于二维情况，我们同样计算两个部分的面积，他们的面积是相等的。其中<!-- -->表示<!-- -->改变<!-- -->时，x_{1}的改变量，<!-- -->表示<!-- -->改变<!-- -->时，<!-- -->的改变量.</div><div class="notion-text notion-block-fff0c0b4c9ec81d6804ec76e4dd184af">那么我们可以逐步推导得到下面的结果：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81b4b36eff7235adce24"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb4966d30-5d4f-4113-b4de-140d1daf2590%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81b4-b36e-ff7235adce24&amp;t=fff0c0b4-c9ec-81b4-b36e-ff7235adce24&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-fff0c0b4c9ec816ab3afc086b1afac3b" data-id="fff0c0b4c9ec816ab3afc086b1afac3b"><span><div id="fff0c0b4c9ec816ab3afc086b1afac3b" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec816ab3afc086b1afac3b" title="Flow-based Model"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Flow-based Model</span></span></h3><div class="notion-text notion-block-fff0c0b4c9ec81a3a646f13a8cc9b798">有了上面的推导结果，我们就可以把Generator的原始分布和生成分布之间的关系写出来，如下图所示。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81d7b4e0e276181d296d"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb17dd56d-01f6-434b-afa8-f3044176d550%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81d7-b4e0-e276181d296d&amp;t=fff0c0b4-c9ec-81d7-b4e0-e276181d296d&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81a1a7bdceef51dce7cf">为了计算<!-- -->, 我们要保证能够计算出生成器的det(<!-- -->). 由于在输入和输出很多维的情况下，Jacobian Matrix会很大，计算量巨大，所以要认真设计Generator的结构。为了保证<!-- -->是可以计算出来的(G是可逆的)，我们要保证输入输出的channel是一致的。如果input z和output x的维度不一致，那么G一定不是可逆的。维度一致不一定可逆。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81c5bc09f6d4678ca1c8"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F16c2093a-ee83-45bf-b2a5-98f4a1f8192b%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81c5-bc09-f6d4678ca1c8&amp;t=fff0c0b4-c9ec-81c5-bc09-f6d4678ca1c8&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81de96badd96e75b073d">由于G的结构是受限制的，所以G的表达能力也是有限的。所以Flow使用了多个G.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec814e9905c5656c3598bc"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd928de4a-bdec-4d5e-b8cd-4494361bb3ca%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-814e-9905-c5656c3598bc&amp;t=fff0c0b4-c9ec-814e-9905-c5656c3598bc&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81a6b8efde227abf3509">那么我们实际上是怎样训练的呢？</div><div class="notion-text notion-block-fff0c0b4c9ec8193bc8bdc8b2288f1a6">以单个G为例：</div><div class="notion-text notion-block-fff0c0b4c9ec818dacb1d289ddf21970">由于我们最大化的目标函数只包含<!-- -->, 而不包含G，所以我们在训练时实际上是训练<!-- -->，然后用G做生成任务。训练时，我们从目标分布中采样<!-- -->, 送到<!-- -->，得到<!-- -->. z的初始化分布为标准正态分布，所以目标函数的第一项会让<!-- -->尽量生成0矩阵，这样loss最小，这样显然不行。如果z一直是零矩阵，不那么雅戈比行列式就会是0，取log就是负无穷，这样就无法最大化目标函数。于是<!-- -->会折中，让生成的z尽量向0靠近，但是不能是零矩阵。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-fff0c0b4c9ec81a8a0e8db6fc7d48a4f" data-id="fff0c0b4c9ec81a8a0e8db6fc7d48a4f"><span><div id="fff0c0b4c9ec81a8a0e8db6fc7d48a4f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81a8a0e8db6fc7d48a4f" title="Coupling layer"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Coupling layer</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec81488337c6e7ae94fb5a">G的结构应该怎么样设才能满足上面提到的要求呢，一种设计是Coupling Layer, 如下图所示。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81b1bdb0fb822eeef9e1"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6f3e109f-2f01-4da0-bb6b-9b4ec519edd5%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81b1-bdb0-fb822eeef9e1&amp;t=fff0c0b4-c9ec-81b1-bdb0-fb822eeef9e1&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8101a20ccb394bb4b910">我们把输入的z分割为两个部分，前一个部分直接复制得到前一个部分的x；然后将前一部分做两个变换，这连个变换任意，多复杂都行，使其能够生成和后一部分长度相同的序列。然后后一部分x的计算如图所示，其中⊙表示的是按位乘运算。</div><div class="notion-text notion-block-fff0c0b4c9ec81679d3dd04815dafb6d">这样设计G能够容易得到G的逆。G_{-1}计算如下图所示：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec817195a2f514c2e885e0"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4adacb99-1f08-4a57-b458-6abd7dcc9fb7%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8171-95a2-f514c2e885e0&amp;t=fff0c0b4-c9ec-8171-95a2-f514c2e885e0&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8124bccfec94521a7133">现在我们还需要计算J(G).Coupling Layer的J也非常好计算.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81009702c295c1cc0eec"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc813d751-b262-421d-939b-ade393353848%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8100-9702-c295c1cc0eec&amp;t=fff0c0b4-c9ec-8100-9702-c295c1cc0eec&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8194a10ff3e0ec459aa2">由于<!-- -->直接由<!-- -->复制得到，所以上图阴影部分左上部分为单位矩阵。由于<!-- -->的变化与<!-- -->无关, 所以阴影部分右上部分为0.所以整个det(J(G))只和阴影部分右下角有关。阴影部分右下角由上图公式可以算出是一个对角阵，行列式的值就是对角元素乘积，也就是<!-- -->.</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-fff0c0b4c9ec8135b1e0d554b52677cd" data-id="fff0c0b4c9ec8135b1e0d554b52677cd"><span><div id="fff0c0b4c9ec8135b1e0d554b52677cd" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec8135b1e0d554b52677cd" title="Coupling layer - stacking"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Coupling layer - stacking</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec818c8a47ee0e48f5414f">当我们叠加多个G时就会出现问题。上面部分会一直复制到最后一层。一个简单的解决方案就是把G上下颠倒。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec818b9cc8f9d67934f923"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fecb5a14f-8a3f-4cb3-8070-a352036c3309%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-818b-9cc8-f9d67934f923&amp;t=fff0c0b4-c9ec-818b-9cc8-f9d67934f923&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec817e82e4c98d1ece80bc">例如在CV中，可以采用单数coupling，双数transform；或者在通道上选择若干通道coupling，若干通道transform。</div><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-fff0c0b4c9ec814baabcf9d0fac22bb5" data-id="fff0c0b4c9ec814baabcf9d0fac22bb5"><span><div id="fff0c0b4c9ec814baabcf9d0fac22bb5" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec814baabcf9d0fac22bb5" title="Glow"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Glow</span></span></h3><div class="notion-text notion-block-fff0c0b4c9ec8118beb0cbf760e704a1">G使用了1*1 convolution.</div><div class="notion-text notion-block-fff0c0b4c9ec81f5bdbeff854791fe31">通俗直观理解：1*1卷积可以交换通道位置，相当于上面stack的方式由机器自己学习。</div><div class="notion-text notion-block-fff0c0b4c9ec815a8848c82498586aca">那么如果卷积的kernel矩阵是可逆的，G就是可逆的。但是W是学习出来的，它一定可逆吗？？不知道，我们只在初始化kernel时设定为一个可逆的矩阵。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec813c9780c3bd25f8f488"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb09b8227-7135-4559-9f26-487511712465%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-813c-9780-c3bd25f8f488&amp;t=fff0c0b4-c9ec-813c-9780-c3bd25f8f488&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81649353ec9f40ebcd29">那么这个G的Jacobian Matrix是什么呢？</div><div class="notion-text notion-block-fff0c0b4c9ec8124a3bddc8c276a7ecc">答案：就是这个kernel matrix.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec819999abe4651e662e89"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F07299c05-4fda-42d3-8d7c-8a802d991dec%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8199-99ab-e4651e662e89&amp;t=fff0c0b4-c9ec-8199-99ab-e4651e662e89&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81b19c57fa90334aa09e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3593290a-2cb5-4ed9-bc87-bb83f6b517cf%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81b1-9c57-fa90334aa09e&amp;t=fff0c0b4-c9ec-81b1-9c57-fa90334aa09e&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec812592deca47a706876b"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F85216d70-ee30-4cfd-84b2-c58245170d55%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8125-92de-ca47a706876b&amp;t=fff0c0b4-c9ec-8125-92de-ca47a706876b&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8181ac09c856d4e80255"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F36088758-8561-4606-a30d-087a118b072f%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8181-ac09-c856d4e80255&amp;t=fff0c0b4-c9ec-8181-ac09-c856d4e80255&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8195879ce47c24e564ab">在语音合成应用：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81c2bacce72654c3fa03"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4a1e7aa4-6132-4cfd-82b0-b2e50327e2e4%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81c2-bacc-e72654c3fa03&amp;t=fff0c0b4-c9ec-81c2-bacc-e72654c3fa03&amp;width=2132&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-blank notion-block-fff0c0b4c9ec81149f26cf20f5622dd1"> </div></main></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[文本前端 ]]></title>
            <link>https://wosyoo.github.io/technology/text-front</link>
            <guid>https://wosyoo.github.io/technology/text-front</guid>
            <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[语音合成文本前端BERT]]></description>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-10a0c0b4c9ec80e9ab91eaa143a47efb"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-a9895ec64e254431a3b951a2e3e195d9" data-id="a9895ec64e254431a3b951a2e3e195d9"><span><div id="a9895ec64e254431a3b951a2e3e195d9" class="notion-header-anchor"></div><a class="notion-hash-link" href="#a9895ec64e254431a3b951a2e3e195d9" title="Bert-Prosody预训练文本提取文本韵律"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Bert-Prosody预训练文本提取文本韵律</span></span></h2><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-e4fa07350ef64b07a1bf0f49d52d4b8d" data-id="e4fa07350ef64b07a1bf0f49d52d4b8d"><span><div id="e4fa07350ef64b07a1bf0f49d52d4b8d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e4fa07350ef64b07a1bf0f49d52d4b8d" title="Chinese-FastSpeech2"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Chinese-FastSpeech2</span></span></h3><div class="notion-text notion-block-5c357864f67d47089cb39e5c6554d0f5">最先将Bert-Prosody用到文本前段韵律提取在：</div><a target="_blank" rel="noopener noreferrer" href="https://github.com/Executedone/Chinese-FastSpeech2" class="notion-external notion-external-block notion-row notion-block-10a0c0b4c9ec80bfaeadc78acf3f9e86"><div class="notion-external-image"><svg viewBox="0 0 260 260"><g><path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z" fill="#161614"></path></g></svg></div><div class="notion-external-description"><div class="notion-external-title">Chinese-FastSpeech2</div><div class="notion-external-subtitle"><span>Executedone</span><span> • </span><span>Updated <!-- -->Sep 26, 2024</span></div></div></a><div class="notion-text notion-block-10a0c0b4c9ec80d5896ae379e75e0516">以下是该模型的结构图：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-0d47302660084064a4a09af135a07e29"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F78905e0e-76ee-4094-8d22-04cf639e7a27%2FUntitled.png?table=block&amp;id=0d473026-6008-4064-a4a0-9af135a07e29&amp;t=0d473026-6008-4064-a4a0-9af135a07e29&amp;width=4161&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-dd9b8bc4473847a99478bbf40c5b3f7d">这个项目基于FastSpeech2，在模型优化上:</div><ul class="notion-list notion-list-disc notion-block-6c92ec0ec6134ecebcbc87138adcdcc4"><li>微调了一个Prosody-Bert;</li></ul><ul class="notion-list notion-list-disc notion-block-61a4419899b942d58c78dc5d5f489380"><li>引入Prosody-Bert的文本特征，丰富Prosody Features;</li></ul><ul class="notion-list notion-list-disc notion-block-883de30b8ac3425eb5328afa12e7c4ba"><li>在Variance Adaptor中加入prosody predictor，控制韵律学习。</li></ul><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-e9af595c2c954e249b6c599d7504d0e8" data-id="e9af595c2c954e249b6c599d7504d0e8"><span><div id="e9af595c2c954e249b6c599d7504d0e8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e9af595c2c954e249b6c599d7504d0e8" title="模型训练流程："><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">模型训练流程：</span></span></h4><div class="notion-text notion-block-d04f2f5bda2c49f79b030bb94f551450">采用公开的在AISHELL3上训练好的fastspeech2模型作为预训练模型，使用biaobei10000女声数据去优化模型；</div><ul class="notion-list notion-list-disc notion-block-bd4d22c869fd4023914c1539a32784b5"><li><b>阶段一（Prosody-Bert训练）</b></li><ul class="notion-list notion-list-disc notion-block-bd4d22c869fd4023914c1539a32784b5"><li>根据标贝数据的韵律标注，将每个字转成对应的韵律标签，如“卡尔普#2陪外孙#1玩滑梯#4。”，对应的标签为“011 011 011 2”，<span class="notion-orange_background">用softmax进行三分类训练</span>；</li></ul></ul><ul class="notion-list notion-list-disc notion-block-0de6a04b76e547e7a296ed1c1ad6ccd0"><li><b>阶段二（Prosody-Fastspeech2训练）</b></li><ul class="notion-list notion-list-disc notion-block-0de6a04b76e547e7a296ed1c1ad6ccd0"><li>加载预训练模型权重，同时初始化prosody predictor权重，在输入端融合prosody char embedding和phoneme embedding，按fastspeech2的方式训练声学模型；</li></ul></ul><ul class="notion-list notion-list-disc notion-block-2c653b6a6fc740108e521173110822ac"><li><b>阶段三（HifiGAN微调）</b></li><ul class="notion-list notion-list-disc notion-block-2c653b6a6fc740108e521173110822ac"><li>加载通用的HifiGAN模型，在标贝10000数据上微调。</li></ul></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-b1728d7786064879a47024fc03169f37" data-id="b1728d7786064879a47024fc03169f37"><span><div id="b1728d7786064879a47024fc03169f37" class="notion-header-anchor"></div><a class="notion-hash-link" href="#b1728d7786064879a47024fc03169f37" title="BERT 预训练模型选择"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">BERT 预训练模型选择</span></span></h3><div class="notion-text notion-block-ac504cab150942b082219d76d15021a1">Chinese-FastSpeech2采用了<code class="notion-inline-code"><b>RoBERTa-wwm-ext, Chinese</b></code><b> </b>模型进行Prosody预训练.</div><div class="notion-text notion-block-457284c81f1742b58d59a87b61d15ddb">“RoBERTa-wwm-ext, Chinese”模型为哈工大讯飞开源的中文预训练模型，其名称包含了训练数据，mask方式等信息。<a target="_blank" rel="noopener noreferrer" href="https://github.com/ymcui/Chinese-BERT-wwm" class="notion-external notion-external-mention"><div class="notion-external-image"><svg viewBox="0 0 260 260"><g><path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z" fill="#161614"></path></g></svg></div><div class="notion-external-description"><div class="notion-external-title">Chinese-BERT-wwm</div><div class="notion-external-subtitle"><span>ymcui</span><span> • </span><span>Updated <!-- -->Sep 26, 2024</span></div></div></a></div><ul class="notion-list notion-list-disc notion-block-d5d1d200864143a8b251a61eeb90d416"><li>RoBERTa: RoBERTa是BERT的改进版，通过改进训练任务和数据生成方式、训练更久、使用更大批次、使用更多数据等获得了State of The Art的效果.</li></ul><ul class="notion-list notion-list-disc notion-block-38e83b35f990451b8a74a097b7fb6dc3"><li>wwm: Whole Word Masking,翻译为<code class="notion-inline-code">全词mask</code>。是谷歌在2019年5月31日发布的一项BERT的升级版本，主要更改了原预训练阶段的训练样本生成策略。 简单来说，原有基于WordPiece的分词方式会把一个完整的词切分成若干个子词，在生成训练样本时，这些被分开的子词会随机被mask。 在<code class="notion-inline-code">全词Mask</code>中，如果一个完整的词的部分WordPiece子词被mask，则同属该词的其他部分也会被mask，即<code class="notion-inline-code">全词Mask</code>。</li><ul class="notion-list notion-list-disc notion-block-38e83b35f990451b8a74a097b7fb6dc3"><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-56b4a6986dbe417ba9c2fa4a7baaa4ac"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F1616912e-61d0-45e3-ac5c-cbaac6f95750%2FUntitled.png?table=block&amp;id=56b4a698-6dbe-417b-a9c2-fa4a7baaa4ac&amp;t=56b4a698-6dbe-417b-a9c2-fa4a7baaa4ac&amp;width=844.9765625&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure></ul></ul><ul class="notion-list notion-list-disc notion-block-7e7316e6c6b445fc90a99e03a8ed6fb0"><li>ext: 训练数据集，EXT数据包括中文维基百科，其他百科、新闻、问答等数据，总词数达5.4B。</li></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-10c39af730bc488d8c786fe05c68eca6" data-id="10c39af730bc488d8c786fe05c68eca6"><span><div id="10c39af730bc488d8c786fe05c68eca6" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10c39af730bc488d8c786fe05c68eca6" title="Bert-Prosody训练细节"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Bert-Prosody训练细节</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-c66b4ee266974a96a603052b1bb404b8" data-id="c66b4ee266974a96a603052b1bb404b8"><span><div id="c66b4ee266974a96a603052b1bb404b8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#c66b4ee266974a96a603052b1bb404b8" title="DataLoader"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">DataLoader</span></span></h4><div class="notion-text notion-block-74628d6f50e4448f8dc878590da8a6d7">Dataset类：</div><div class="notion-text notion-block-313f80ed1def4a2c9700ca1de62dde4a">输入:文本token以及label</div><div class="notion-text notion-block-a876a60dfd9b49ac92f4df427ff772ac">输出：</div><ul class="notion-list notion-list-disc notion-block-f98b1c7205b34992b42130cd0b6bb706"><li>inputs_ids: 文本token编码的结果，一个batch内长度一样，长度不一致末尾补0</li></ul><ul class="notion-list notion-list-disc notion-block-0335bc04d76249ff9700b25f3c05dd65"><li>inputs_masks: 掩码，有数据为1，没数据为0</li></ul><ul class="notion-list notion-list-disc notion-block-627912316fd84a66b48b578d42ca7112"><li>tokens_type_ids: 全0</li></ul><ul class="notion-list notion-list-disc notion-block-b4ae45899dfe4581ada7f66f6ccbe3c5"><li>label: 三分类韵律标签</li></ul><div class="notion-text notion-block-9ea86f8f09bb4563a2e6bd8a5da9ab81">以下是一个文本输入的实例(batch_size=2)：</div><div class="notion-text notion-block-90260c22b9d24ce7baaa5d378f416334">labels来源：</div><div class="notion-text notion-block-2ccc22942dc9421596315f360b1fbc6f">根据单句分词结果，分块编号。每个块起始位置编号都是0，非起始位置编号为1.句中遇到标点符号编号为2.(所有单句的末尾都含有句号)</div><div class="notion-text notion-block-1dfd84834ba74e09a5e9a84f9d31fce6">示例：</div><div class="notion-text notion-block-e2b6eaeddf774178b94166a668a8cd1c">&quot;text&quot;: &quot;眼眶宽阔而低矮，鼻短而宽。&quot;,</div><div class="notion-text notion-block-1e666806c4564efa9d9b843894ae8444">分词结果：             [眼眶   宽阔   而   低矮   ，   鼻短   而宽   。]</div><div class="notion-text notion-block-9fb462fb90214a35b099f88818eec2b5"> &quot;prosody_label&quot;:  [0, 1,    0, 1,   0,   0, 1,  2,    0, 1,    0, 1,  2  ]</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-57da7a1fa5154ee2b06a6ad25a2e2efb" data-id="57da7a1fa5154ee2b06a6ad25a2e2efb"><span><div id="57da7a1fa5154ee2b06a6ad25a2e2efb" class="notion-header-anchor"></div><a class="notion-hash-link" href="#57da7a1fa5154ee2b06a6ad25a2e2efb" title="Prosody Model"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Prosody Model</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-ff13b38a1bac48718da8a0e3c945c7f2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:672px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F9d17d415-4805-4db2-a68e-7f5e98be138a%2FUntitled.png?table=block&amp;id=ff13b38a-1bac-4871-8da8-a0e3c945c7f2&amp;t=ff13b38a-1bac-4871-8da8-a0e3c945c7f2&amp;width=672&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-b496a7fe8c8b4cd2843ee548fe899843"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:576px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F16d6a6ba-191a-43d8-95e5-746e31948f04%2FUntitled.png?table=block&amp;id=b496a7fe-8c8b-4cd2-843e-e548fe899843&amp;t=b496a7fe-8c8b-4cd2-843e-e548fe899843&amp;width=576&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-f271d9989d274c0d8e772dd8851be463">最终每个字符token都得到一个1*3的向量，用这个向量和labels做交叉熵损失，训练文本的韵律。</div><div class="notion-text notion-block-d0f58e0d79ca43578103d70e846c4f88">训练时参数更新只更新bert后面的两个线性层。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-edc1ed29e63b415c899d3111d2d9069f" data-id="edc1ed29e63b415c899d3111d2d9069f"><span><div id="edc1ed29e63b415c899d3111d2d9069f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#edc1ed29e63b415c899d3111d2d9069f" title="如何使用训练好的BERT-Prosody？"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">如何使用训练好的BERT-Prosody？</span></span></h4><div class="notion-text notion-block-c71516b15a1c40a7a3db17ea1d4363ef">在训练声学模型时，prosody和文本phoneme embedding concat一起作为先验知识送入模型中。但是此时不使用ProsodyModel的第二个Linear Layer，只使用第一个，即生成的tensor大小为N*max_len*256.</div><div class="notion-blank notion-block-c5ffb87ce27c4ac19bbf34c4bfcc8763"> </div></main></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vision Transformer]]></title>
            <link>https://wosyoo.github.io/technology/vit</link>
            <guid>https://wosyoo.github.io/technology/vit</guid>
            <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec819aaa3ad8a27fbc8807"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-blank notion-block-fff0c0b4c9ec816b8c9ad3b21497a8b9"> </div></main></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Transformer]]></title>
            <link>https://wosyoo.github.io/technology/transformer</link>
            <guid>https://wosyoo.github.io/technology/transformer</guid>
            <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec8170a3dbe2247a972ea3"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-text notion-block-fff0c0b4c9ec81b590acd04bb6c13841"><b>参考资料：</b></div><div class="notion-text notion-block-fff0c0b4c9ec81638623d55b15aac046"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://zhuanlan.zhihu.com/p/338817680">Transformer模型详解（图解最完整版） - 知乎 (zhihu.com)</a></div><div class="notion-text notion-block-fff0c0b4c9ec81fcb4fbda33f127472e"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://www.bilibili.com/video/BV1o44y1Y7cp/?spm_id_from=333.788&amp;vd_source=3c8b956b7f9637a100dfb9d16c7b8d5d">18、深入剖析PyTorch中的Transformer API源码_哔哩哔哩_bilibili</a></div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec819bb287c397fa4b1fb1"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F661e070b-4f54-46f8-80bf-db24ba6d8c84%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-819b-b287-c397fa4b1fb1&amp;t=fff0c0b4-c9ec-819b-b287-c397fa4b1fb1&amp;width=432&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec810990eadbfdbf0e9292"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:1296px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F14d2cddf-847f-4297-9e1e-bb4bdedd7222%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8109-90ea-dbfdbf0e9292&amp;t=fff0c0b4-c9ec-8109-90ea-dbfdbf0e9292&amp;width=1296&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81a58b83ca2c8a4aa3c0"><b>transformer pytorch api使用：</b></div><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-fff0c0b4c9ec8190b341f6aded0d1da3" href="https://blog.csdn.net/zhaohongfei_358/article/details/126019181"><div><div class="notion-bookmark-title">Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解_iioSnail的博客-CSDN博客</div><div class="notion-bookmark-description">1. Transformer的训练过程讲解2. Transformer的推理过程讲解3. Transformer的入参和出参讲解4. nn.Transformer的各个参数讲解5. nn.Transformer的mask机制详解6. 实战：使用nn.Transformer训练一个copy任务。_nn.transformer</div><div class="notion-bookmark-link"><div class="notion-bookmark-link-icon"><img src="https://www.notion.so/image/https%3A%2F%2Fg.csdnimg.cn%2Fstatic%2Flogo%2Ffavicon32.ico?table=block&amp;id=fff0c0b4-c9ec-8190-b341-f6aded0d1da3&amp;t=fff0c0b4-c9ec-8190-b341-f6aded0d1da3" alt="Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解_iioSnail的博客-CSDN博客" loading="lazy" decoding="async"/></div><div class="notion-bookmark-link-text">https://blog.csdn.net/zhaohongfei_358/article/details/126019181</div></div></div></a></div><div class="notion-blank notion-block-fff0c0b4c9ec813f826ff308f8d967ca"> </div></main></div>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[VAE]]></title>
            <link>https://wosyoo.github.io/technology/vae</link>
            <guid>https://wosyoo.github.io/technology/vae</guid>
            <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-full-width notion-block-fff0c0b4c9ec8102a8dac18ae9a78bb1"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81aa8854f8f28d8c0c01"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F2eb2cef1-8f73-4663-b4e4-cf1cbf4287cd%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81aa-8854-f8f28d8c0c01&amp;t=fff0c0b4-c9ec-81aa-8854-f8f28d8c0c01&amp;width=2062&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec817f9413f53ecd3b248f"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F6c3e45cb-a045-4d63-8b6f-7f4699472d23%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-817f-9413-f53ecd3b248f&amp;t=fff0c0b4-c9ec-817f-9413-f53ecd3b248f&amp;width=519.9765625&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8164bc4cd086d7bd9aca"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F87412ddd-2baf-4782-957b-a231908b8703%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8164-bc4c-d086d7bd9aca&amp;t=fff0c0b4-c9ec-8164-bc4c-d086d7bd9aca&amp;width=519.9453125&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-blank notion-block-fff0c0b4c9ec8101a0aacfe4935227ed"> </div></main></div>]]></content:encoded>
        </item>
    </channel>
</rss>