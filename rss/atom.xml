<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id/>
    <title>Guagua’s Notion 主页</title>
    <updated>2024-09-25T23:52:32.131Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>学习小呆呱</name>
        <email>sywang027@gmail.com</email>
        <uri>https://wosyoo.github.io</uri>
    </author>
    <link rel="alternate" href="https://wosyoo.github.io/"/>
    <subtitle>一个NotionNext搭建的博客</subtitle>
    <icon>https://wosyoo.github.io/favicon.png</icon>
    <rights>All rights reserved 2024, 学习小呆呱</rights>
    <entry>
        <title type="html"><![CDATA[CosyVoice]]></title>
        <id>https://wosyoo.github.io/technology/cosyvoice</id>
        <link href="https://wosyoo.github.io/technology/cosyvoice"/>
        <updated>2024-09-24T00:00:00.000Z</updated>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-10b0c0b4c9ec80359b3ac0252b0c56de"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-ffe7a9de5b7c412d8711311fbacea28d" data-id="ffe7a9de5b7c412d8711311fbacea28d"><span><div id="ffe7a9de5b7c412d8711311fbacea28d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#ffe7a9de5b7c412d8711311fbacea28d" title="📝 CosyVoice"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">📝 CosyVoice</span></span></h2><blockquote class="notion-quote notion-block-10b0c0b4c9ec806aa527eb8e7f7bce39"><div>一种基于监督语义令牌的可扩展多语言零样本TTS模型</div></blockquote><div class="notion-text notion-block-10b0c0b4c9ec800388e3d2546d6c6d5d">作者单位：Alibaba Speech Lab</div><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-10b0c0b4c9ec80a9b431e681f007845a" data-id="10b0c0b4c9ec80a9b431e681f007845a"><span><div id="10b0c0b4c9ec80a9b431e681f007845a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80a9b431e681f007845a" title="论文阅读"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">论文阅读</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-10b0c0b4c9ec80b7b3a2c4462f7c6a79" data-id="10b0c0b4c9ec80b7b3a2c4462f7c6a79"><span><div id="10b0c0b4c9ec80b7b3a2c4462f7c6a79" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80b7b3a2c4462f7c6a79" title="1.Abstract"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">1.Abstract</span></span></h4><div class="notion-text notion-block-10b0c0b4c9ec80c2b2ece1b97378bbdf">最近LLM-Based TTS以其高自然度和zero-shot能力成为语音合成模型的主流。</div><div class="notion-text notion-block-10b0c0b4c9ec805cba6be65c7d8106b1">在这种TTS范式中，语音信号会被离散成tokens序列，并以文本作为prompt进行合成。所以这种tokens序列的建模非常重要。当前的tokens提取一般是无监督的方式学习的，缺乏明确的语义信息和与文本的对齐。本文希望通过有监督的tokens来建模语音，tokens来自多语言语音识别模型，通过在编码器中插入矢量量化来获得。基于这些有监督tokens，文章提出了一个用于语音生成的基于编解码器的合成器CosyVoice，它由一个用于文本到tokens的LLM和一个用于tokens到语音的条件流匹配模型组成。实验结果表明，zero-shot语音克隆中，有监督语义标记在内容一致性和说话人相似度方面明显优于现有的无监督语义标记。此外，文章发现利用大规模数据进一步提高了合成性能，表明了CosyVoice的可扩展能力。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-10b0c0b4c9ec80cea22ae661a70eefc8" data-id="10b0c0b4c9ec80cea22ae661a70eefc8"><span><div id="10b0c0b4c9ec80cea22ae661a70eefc8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10b0c0b4c9ec80cea22ae661a70eefc8" title="2.Introduction"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">2.Introduction</span></span></h4><div class="notion-text notion-block-10b0c0b4c9ec80bc88cee1da71bc7872">本文的创新点总结：</div><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec808da164fa2ae6effff2"><li>第一个将有监督的tokens集成到TTS当中；</li></ul><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec8001a361f700ca2da9a3"><li>通过text-to-tokens的LLM和tokens-to-speech的条件流匹配两个模块，无需额外的音素提取器和文本-音频强制对齐器；</li></ul><ul class="notion-list notion-list-disc notion-block-10b0c0b4c9ec80bca9e7f50239c1f67e"><li>将x-vectors纳入LLM，把语音分解为语义、说话人和韵律。LLM对语义内容和韵律进行建模，而条件流匹配模型捕获音色和环境信息。</li></ul><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-46bee8c7febe44769fa8e17eb4ab6ca6" data-id="46bee8c7febe44769fa8e17eb4ab6ca6"><span><div id="46bee8c7febe44769fa8e17eb4ab6ca6" class="notion-header-anchor"></div><a class="notion-hash-link" href="#46bee8c7febe44769fa8e17eb4ab6ca6" title="3.Method"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">3.Method</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-10b0c0b4c9ec8083a996eab8e8e2a95a"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fd459e854-7813-4d92-9421-b7536b5eded8%2Fimage.png?table=block&amp;id=10b0c0b4-c9ec-8083-a996-eab8e8e2a95a&amp;t=10b0c0b4-c9ec-8083-a996-eab8e8e2a95a&amp;width=707.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-10b0c0b4c9ec8081b23bff2d5b1613e7">3.1 自监督tokens</div><div class="notion-blank notion-block-10b0c0b4c9ec800b81b5f19448ad9e87"> </div><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-27118e60fdd9448ba3f4f2a5189f1baa" data-id="27118e60fdd9448ba3f4f2a5189f1baa"><span><div id="27118e60fdd9448ba3f4f2a5189f1baa" class="notion-header-anchor"></div><a class="notion-hash-link" href="#27118e60fdd9448ba3f4f2a5189f1baa" title="观点1"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">观点1</span></span></h3><blockquote class="notion-quote notion-block-87995acedc914e95a297b477bdd548bf"><div>引用的话语</div></blockquote><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-10969568f7594b788ffacf88e69a3cb2" data-id="10969568f7594b788ffacf88e69a3cb2"><span><div id="10969568f7594b788ffacf88e69a3cb2" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10969568f7594b788ffacf88e69a3cb2" title="观点2"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">观点2</span></span></h3><blockquote class="notion-quote notion-block-0b8ba6c0766c486da12b277161ed9f55"><div>引用的话语</div></blockquote><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-81e2e65388fb4fb2a1bb1b12b2d6b58a" data-id="81e2e65388fb4fb2a1bb1b12b2d6b58a"><span><div id="81e2e65388fb4fb2a1bb1b12b2d6b58a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#81e2e65388fb4fb2a1bb1b12b2d6b58a" title="🤗 总结归纳"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">🤗 总结归纳</span></span></h2><div class="notion-text notion-block-b51f8830327f458b940061447e7cffaf">总结文章的内容</div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-937f57499485462db659291f119d6614" data-id="937f57499485462db659291f119d6614"><span><div id="937f57499485462db659291f119d6614" class="notion-header-anchor"></div><a class="notion-hash-link" href="#937f57499485462db659291f119d6614" title="📎 参考文章"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">📎 参考文章</span></span></h2><ul class="notion-list notion-list-disc notion-block-8d2d21d29d31425a96e3a7d6ca9ef29f"><li>一些引用</li></ul><ul class="notion-list notion-list-disc notion-block-8b492ecc89b944bb97cf9281576afcfa"><li>引用文章</li></ul><div class="notion-blank notion-block-8045f4d4b7bb4a458fb56e849bdb3e6c"> </div><div class="notion-callout notion-gray_background_co notion-block-c6f8869dfcd142faa7c58a52f183f272"><div class="notion-page-icon-inline notion-page-icon-span"><span class="notion-page-icon" role="img" aria-label="💡">💡</span></div><div class="notion-callout-text">有关Notion安装或者使用上的问题，欢迎您在底部评论区留言，一起交流~</div></div></main></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[文本前端 ]]></title>
        <id>https://wosyoo.github.io/technology/text-front</id>
        <link href="https://wosyoo.github.io/technology/text-front"/>
        <updated>2024-09-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[语音合成文本前端BERT]]></summary>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-10a0c0b4c9ec80e9ab91eaa143a47efb"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><h2 class="notion-h notion-h1 notion-h-indent-0 notion-block-a9895ec64e254431a3b951a2e3e195d9" data-id="a9895ec64e254431a3b951a2e3e195d9"><span><div id="a9895ec64e254431a3b951a2e3e195d9" class="notion-header-anchor"></div><a class="notion-hash-link" href="#a9895ec64e254431a3b951a2e3e195d9" title="Bert-Prosody预训练文本提取文本韵律"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Bert-Prosody预训练文本提取文本韵律</span></span></h2><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-e4fa07350ef64b07a1bf0f49d52d4b8d" data-id="e4fa07350ef64b07a1bf0f49d52d4b8d"><span><div id="e4fa07350ef64b07a1bf0f49d52d4b8d" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e4fa07350ef64b07a1bf0f49d52d4b8d" title="Chinese-FastSpeech2"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Chinese-FastSpeech2</span></span></h3><div class="notion-text notion-block-5c357864f67d47089cb39e5c6554d0f5">最先将Bert-Prosody用到文本前段韵律提取在：</div><a target="_blank" rel="noopener noreferrer" href="https://github.com/Executedone/Chinese-FastSpeech2" class="notion-external notion-external-block notion-row notion-block-10a0c0b4c9ec80bfaeadc78acf3f9e86"><div class="notion-external-image"><svg viewBox="0 0 260 260"><g><path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z" fill="#161614"></path></g></svg></div><div class="notion-external-description"><div class="notion-external-title">Chinese-FastSpeech2</div><div class="notion-external-subtitle"><span>Executedone</span><span> • </span><span>Updated <!-- -->Sep 20, 2024</span></div></div></a><div class="notion-text notion-block-10a0c0b4c9ec80d5896ae379e75e0516">以下是该模型的结构图：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-0d47302660084064a4a09af135a07e29"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F78905e0e-76ee-4094-8d22-04cf639e7a27%2FUntitled.png?table=block&amp;id=0d473026-6008-4064-a4a0-9af135a07e29&amp;t=0d473026-6008-4064-a4a0-9af135a07e29&amp;width=4161&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-dd9b8bc4473847a99478bbf40c5b3f7d">这个项目基于FastSpeech2，在模型优化上:</div><ul class="notion-list notion-list-disc notion-block-6c92ec0ec6134ecebcbc87138adcdcc4"><li>微调了一个Prosody-Bert;</li></ul><ul class="notion-list notion-list-disc notion-block-61a4419899b942d58c78dc5d5f489380"><li>引入Prosody-Bert的文本特征，丰富Prosody Features;</li></ul><ul class="notion-list notion-list-disc notion-block-883de30b8ac3425eb5328afa12e7c4ba"><li>在Variance Adaptor中加入prosody predictor，控制韵律学习。</li></ul><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-e9af595c2c954e249b6c599d7504d0e8" data-id="e9af595c2c954e249b6c599d7504d0e8"><span><div id="e9af595c2c954e249b6c599d7504d0e8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e9af595c2c954e249b6c599d7504d0e8" title="模型训练流程："><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">模型训练流程：</span></span></h4><div class="notion-text notion-block-d04f2f5bda2c49f79b030bb94f551450">采用公开的在AISHELL3上训练好的fastspeech2模型作为预训练模型，使用biaobei10000女声数据去优化模型；</div><ul class="notion-list notion-list-disc notion-block-bd4d22c869fd4023914c1539a32784b5"><li><b>阶段一（Prosody-Bert训练）</b></li><ul class="notion-list notion-list-disc notion-block-bd4d22c869fd4023914c1539a32784b5"><li>根据标贝数据的韵律标注，将每个字转成对应的韵律标签，如“卡尔普#2陪外孙#1玩滑梯#4。”，对应的标签为“011 011 011 2”，<span class="notion-orange_background">用softmax进行三分类训练</span>；</li></ul></ul><ul class="notion-list notion-list-disc notion-block-0de6a04b76e547e7a296ed1c1ad6ccd0"><li><b>阶段二（Prosody-Fastspeech2训练）</b></li><ul class="notion-list notion-list-disc notion-block-0de6a04b76e547e7a296ed1c1ad6ccd0"><li>加载预训练模型权重，同时初始化prosody predictor权重，在输入端融合prosody char embedding和phoneme embedding，按fastspeech2的方式训练声学模型；</li></ul></ul><ul class="notion-list notion-list-disc notion-block-2c653b6a6fc740108e521173110822ac"><li><b>阶段三（HifiGAN微调）</b></li><ul class="notion-list notion-list-disc notion-block-2c653b6a6fc740108e521173110822ac"><li>加载通用的HifiGAN模型，在标贝10000数据上微调。</li></ul></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-b1728d7786064879a47024fc03169f37" data-id="b1728d7786064879a47024fc03169f37"><span><div id="b1728d7786064879a47024fc03169f37" class="notion-header-anchor"></div><a class="notion-hash-link" href="#b1728d7786064879a47024fc03169f37" title="BERT 预训练模型选择"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">BERT 预训练模型选择</span></span></h3><div class="notion-text notion-block-ac504cab150942b082219d76d15021a1">Chinese-FastSpeech2采用了<code class="notion-inline-code"><b>RoBERTa-wwm-ext, Chinese</b></code><b> </b>模型进行Prosody预训练.</div><div class="notion-text notion-block-457284c81f1742b58d59a87b61d15ddb">“RoBERTa-wwm-ext, Chinese”模型为哈工大讯飞开源的中文预训练模型，其名称包含了训练数据，mask方式等信息。<a target="_blank" rel="noopener noreferrer" href="https://github.com/ymcui/Chinese-BERT-wwm" class="notion-external notion-external-mention"><div class="notion-external-image"><svg viewBox="0 0 260 260"><g><path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z" fill="#161614"></path></g></svg></div><div class="notion-external-description"><div class="notion-external-title">Chinese-BERT-wwm</div><div class="notion-external-subtitle"><span>ymcui</span><span> • </span><span>Updated <!-- -->Sep 23, 2024</span></div></div></a></div><ul class="notion-list notion-list-disc notion-block-d5d1d200864143a8b251a61eeb90d416"><li>RoBERTa: RoBERTa是BERT的改进版，通过改进训练任务和数据生成方式、训练更久、使用更大批次、使用更多数据等获得了State of The Art的效果.</li></ul><ul class="notion-list notion-list-disc notion-block-38e83b35f990451b8a74a097b7fb6dc3"><li>wwm: Whole Word Masking,翻译为<code class="notion-inline-code">全词mask</code>。是谷歌在2019年5月31日发布的一项BERT的升级版本，主要更改了原预训练阶段的训练样本生成策略。 简单来说，原有基于WordPiece的分词方式会把一个完整的词切分成若干个子词，在生成训练样本时，这些被分开的子词会随机被mask。 在<code class="notion-inline-code">全词Mask</code>中，如果一个完整的词的部分WordPiece子词被mask，则同属该词的其他部分也会被mask，即<code class="notion-inline-code">全词Mask</code>。</li><ul class="notion-list notion-list-disc notion-block-38e83b35f990451b8a74a097b7fb6dc3"><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-56b4a6986dbe417ba9c2fa4a7baaa4ac"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F1616912e-61d0-45e3-ac5c-cbaac6f95750%2FUntitled.png?table=block&amp;id=56b4a698-6dbe-417b-a9c2-fa4a7baaa4ac&amp;t=56b4a698-6dbe-417b-a9c2-fa4a7baaa4ac&amp;width=844.9765625&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure></ul></ul><ul class="notion-list notion-list-disc notion-block-7e7316e6c6b445fc90a99e03a8ed6fb0"><li>ext: 训练数据集，EXT数据包括中文维基百科，其他百科、新闻、问答等数据，总词数达5.4B。</li></ul><h3 class="notion-h notion-h2 notion-h-indent-1 notion-block-10c39af730bc488d8c786fe05c68eca6" data-id="10c39af730bc488d8c786fe05c68eca6"><span><div id="10c39af730bc488d8c786fe05c68eca6" class="notion-header-anchor"></div><a class="notion-hash-link" href="#10c39af730bc488d8c786fe05c68eca6" title="Bert-Prosody训练细节"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Bert-Prosody训练细节</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-c66b4ee266974a96a603052b1bb404b8" data-id="c66b4ee266974a96a603052b1bb404b8"><span><div id="c66b4ee266974a96a603052b1bb404b8" class="notion-header-anchor"></div><a class="notion-hash-link" href="#c66b4ee266974a96a603052b1bb404b8" title="DataLoader"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">DataLoader</span></span></h4><div class="notion-text notion-block-74628d6f50e4448f8dc878590da8a6d7">Dataset类：</div><div class="notion-text notion-block-313f80ed1def4a2c9700ca1de62dde4a">输入:文本token以及label</div><div class="notion-text notion-block-a876a60dfd9b49ac92f4df427ff772ac">输出：</div><ul class="notion-list notion-list-disc notion-block-f98b1c7205b34992b42130cd0b6bb706"><li>inputs_ids: 文本token编码的结果，一个batch内长度一样，长度不一致末尾补0</li></ul><ul class="notion-list notion-list-disc notion-block-0335bc04d76249ff9700b25f3c05dd65"><li>inputs_masks: 掩码，有数据为1，没数据为0</li></ul><ul class="notion-list notion-list-disc notion-block-627912316fd84a66b48b578d42ca7112"><li>tokens_type_ids: 全0</li></ul><ul class="notion-list notion-list-disc notion-block-b4ae45899dfe4581ada7f66f6ccbe3c5"><li>label: 三分类韵律标签</li></ul><div class="notion-text notion-block-9ea86f8f09bb4563a2e6bd8a5da9ab81">以下是一个文本输入的实例(batch_size=2)：</div><div class="notion-text notion-block-90260c22b9d24ce7baaa5d378f416334">labels来源：</div><div class="notion-text notion-block-2ccc22942dc9421596315f360b1fbc6f">根据单句分词结果，分块编号。每个块起始位置编号都是0，非起始位置编号为1.句中遇到标点符号编号为2.(所有单句的末尾都含有句号)</div><div class="notion-text notion-block-1dfd84834ba74e09a5e9a84f9d31fce6">示例：</div><div class="notion-text notion-block-e2b6eaeddf774178b94166a668a8cd1c">&quot;text&quot;: &quot;眼眶宽阔而低矮，鼻短而宽。&quot;,</div><div class="notion-text notion-block-1e666806c4564efa9d9b843894ae8444">分词结果：             [眼眶   宽阔   而   低矮   ，   鼻短   而宽   。]</div><div class="notion-text notion-block-9fb462fb90214a35b099f88818eec2b5"> &quot;prosody_label&quot;:  [0, 1,    0, 1,   0,   0, 1,  2,    0, 1,    0, 1,  2  ]</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-57da7a1fa5154ee2b06a6ad25a2e2efb" data-id="57da7a1fa5154ee2b06a6ad25a2e2efb"><span><div id="57da7a1fa5154ee2b06a6ad25a2e2efb" class="notion-header-anchor"></div><a class="notion-hash-link" href="#57da7a1fa5154ee2b06a6ad25a2e2efb" title="Prosody Model"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Prosody Model</span></span></h4><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-ff13b38a1bac48718da8a0e3c945c7f2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:672px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F9d17d415-4805-4db2-a68e-7f5e98be138a%2FUntitled.png?table=block&amp;id=ff13b38a-1bac-4871-8da8-a0e3c945c7f2&amp;t=ff13b38a-1bac-4871-8da8-a0e3c945c7f2&amp;width=672&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-b496a7fe8c8b4cd2843ee548fe899843"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:576px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F16d6a6ba-191a-43d8-95e5-746e31948f04%2FUntitled.png?table=block&amp;id=b496a7fe-8c8b-4cd2-843e-e548fe899843&amp;t=b496a7fe-8c8b-4cd2-843e-e548fe899843&amp;width=576&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-f271d9989d274c0d8e772dd8851be463">最终每个字符token都得到一个1*3的向量，用这个向量和labels做交叉熵损失，训练文本的韵律。</div><div class="notion-text notion-block-d0f58e0d79ca43578103d70e846c4f88">训练时参数更新只更新bert后面的两个线性层。</div><h4 class="notion-h notion-h3 notion-h-indent-2 notion-block-edc1ed29e63b415c899d3111d2d9069f" data-id="edc1ed29e63b415c899d3111d2d9069f"><span><div id="edc1ed29e63b415c899d3111d2d9069f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#edc1ed29e63b415c899d3111d2d9069f" title="如何使用训练好的BERT-Prosody？"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">如何使用训练好的BERT-Prosody？</span></span></h4><div class="notion-text notion-block-c71516b15a1c40a7a3db17ea1d4363ef">在训练声学模型时，prosody和文本phoneme embedding concat一起作为先验知识送入模型中。但是此时不使用ProsodyModel的第二个Linear Layer，只使用第一个，即生成的tensor大小为N*max_len*256.</div><div class="notion-blank notion-block-c5ffb87ce27c4ac19bbf34c4bfcc8763"> </div></main></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vision Transformer]]></title>
        <id>https://wosyoo.github.io/technology/vit</id>
        <link href="https://wosyoo.github.io/technology/vit"/>
        <updated>2024-09-23T00:00:00.000Z</updated>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec819aaa3ad8a27fbc8807"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-blank notion-block-fff0c0b4c9ec816b8c9ad3b21497a8b9"> </div></main></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer]]></title>
        <id>https://wosyoo.github.io/technology/transformer</id>
        <link href="https://wosyoo.github.io/technology/transformer"/>
        <updated>2024-09-23T00:00:00.000Z</updated>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec8170a3dbe2247a972ea3"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-text notion-block-fff0c0b4c9ec81b590acd04bb6c13841"><b>参考资料：</b></div><div class="notion-text notion-block-fff0c0b4c9ec81638623d55b15aac046"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://zhuanlan.zhihu.com/p/338817680">Transformer模型详解（图解最完整版） - 知乎 (zhihu.com)</a></div><div class="notion-text notion-block-fff0c0b4c9ec81fcb4fbda33f127472e"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="https://www.bilibili.com/video/BV1o44y1Y7cp/?spm_id_from=333.788&amp;vd_source=3c8b956b7f9637a100dfb9d16c7b8d5d">18、深入剖析PyTorch中的Transformer API源码_哔哩哔哩_bilibili</a></div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec819bb287c397fa4b1fb1"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F661e070b-4f54-46f8-80bf-db24ba6d8c84%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-819b-b287-c397fa4b1fb1&amp;t=fff0c0b4-c9ec-819b-b287-c397fa4b1fb1&amp;width=432&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec810990eadbfdbf0e9292"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:1296px;max-width:100%;flex-direction:column"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F14d2cddf-847f-4297-9e1e-bb4bdedd7222%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8109-90ea-dbfdbf0e9292&amp;t=fff0c0b4-c9ec-8109-90ea-dbfdbf0e9292&amp;width=1296&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81a58b83ca2c8a4aa3c0"><b>transformer pytorch api使用：</b></div><div class="notion-row"><a target="_blank" rel="noopener noreferrer" class="notion-bookmark notion-block-fff0c0b4c9ec8190b341f6aded0d1da3" href="https://blog.csdn.net/zhaohongfei_358/article/details/126019181"><div><div class="notion-bookmark-title">Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解_iioSnail的博客-CSDN博客</div><div class="notion-bookmark-description">1. Transformer的训练过程讲解2. Transformer的推理过程讲解3. Transformer的入参和出参讲解4. nn.Transformer的各个参数讲解5. nn.Transformer的mask机制详解6. 实战：使用nn.Transformer训练一个copy任务。_nn.transformer</div><div class="notion-bookmark-link"><div class="notion-bookmark-link-icon"><img src="https://www.notion.so/image/https%3A%2F%2Fg.csdnimg.cn%2Fstatic%2Flogo%2Ffavicon32.ico?table=block&amp;id=fff0c0b4-c9ec-8190-b341-f6aded0d1da3&amp;t=fff0c0b4-c9ec-8190-b341-f6aded0d1da3" alt="Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解_iioSnail的博客-CSDN博客" loading="lazy" decoding="async"/></div><div class="notion-bookmark-link-text">https://blog.csdn.net/zhaohongfei_358/article/details/126019181</div></div></div></a></div><div class="notion-blank notion-block-fff0c0b4c9ec813f826ff308f8d967ca"> </div></main></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[VAE]]></title>
        <id>https://wosyoo.github.io/technology/vae</id>
        <link href="https://wosyoo.github.io/technology/vae"/>
        <updated>2024-09-23T00:00:00.000Z</updated>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-full-width notion-block-fff0c0b4c9ec8102a8dac18ae9a78bb1"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81aa8854f8f28d8c0c01"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F2eb2cef1-8f73-4663-b4e4-cf1cbf4287cd%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81aa-8854-f8f28d8c0c01&amp;t=fff0c0b4-c9ec-81aa-8854-f8f28d8c0c01&amp;width=2062&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec817f9413f53ecd3b248f"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F6c3e45cb-a045-4d63-8b6f-7f4699472d23%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-817f-9413-f53ecd3b248f&amp;t=fff0c0b4-c9ec-817f-9413-f53ecd3b248f&amp;width=519.9765625&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8164bc4cd086d7bd9aca"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F87412ddd-2baf-4782-957b-a231908b8703%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8164-bc4c-d086d7bd9aca&amp;t=fff0c0b4-c9ec-8164-bc4c-d086d7bd9aca&amp;width=519.9453125&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-blank notion-block-fff0c0b4c9ec8101a0aacfe4935227ed"> </div></main></div>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diffusion model]]></title>
        <id>https://wosyoo.github.io/technology/diffusion</id>
        <link href="https://wosyoo.github.io/technology/diffusion"/>
        <updated>2024-09-23T00:00:00.000Z</updated>
        <content type="html"><![CDATA[<div id="notion-article" class="mx-auto overflow-hidden "><main class="notion light-mode notion-page notion-block-fff0c0b4c9ec813fa9f5d6ee51d583f4"><div class="notion-viewport"></div><div class="notion-collection-page-properties"></div><div class="notion-text notion-block-fff0c0b4c9ec81598e5ad5b88b03e164">Denoising Diffusion Probabilistic Models简称Diffusion model.</div><h3 class="notion-h notion-h2 notion-h-indent-0 notion-block-fff0c0b4c9ec81b3a6c3ed1076c5e3c7" data-id="fff0c0b4c9ec81b3a6c3ed1076c5e3c7"><span><div id="fff0c0b4c9ec81b3a6c3ed1076c5e3c7" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81b3a6c3ed1076c5e3c7" title="Diffusion Model概念"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Diffusion Model概念</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec81de9675ebadc1adddab" data-id="fff0c0b4c9ec81de9675ebadc1adddab"><span><div id="fff0c0b4c9ec81de9675ebadc1adddab" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81de9675ebadc1adddab" title="Diffusion model如何运作"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Diffusion model如何运作</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec81ecb816d873da4e5fa9">假如我们要生成一张100*100的图像，那么我们先从一个正态分布中采样100*100个pixel，然后进行denoise去噪声化一步步生成最终清晰的图片，这个过程叫做<b>reverse process</b>.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81018aaedc0ca77989fb"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F1cbc4a81-4c0d-401d-a97b-4b0f05e5b992%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8101-8aae-dc0ca77989fb&amp;t=fff0c0b4-c9ec-8101-8aae-dc0ca77989fb&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81de9f17e7a29b319d2a">我们会复用这个denoise model，每一步生成的图片都送入到一个denoise model去除噪声。但是由于每个阶段的图片noise的程度是不同的，所以我们要在denoise model输入加上step(这个step其实是含噪声的程度，由大到小)。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81a2be30cb081b41aaa2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F40a4f995-39a7-4c34-99a0-2244b944ab4e%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81a2-be30-cb081b41aaa2&amp;t=fff0c0b4-c9ec-81a2-be30-cb081b41aaa2&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec817fb65cdfb09622b940"><b>denoise model里面到底长啥样？</b></div><div class="notion-text notion-block-fff0c0b4c9ec81b99494ca6e17cd4c3e">denoise model包含两个输入，其中一个为图片，另一个为step。里面包含一个noise predictor，用来预测输入图片的噪声，noise predictor会输出一个预测这个图片的noise，那么我们在原图上减去这个noise就能得到去除噪声后的图片。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec815cb683f5628f253d86"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F8ac73da0-b0d1-4b8a-a2dc-467d4a613c7c%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-815c-b683-f5628f253d86&amp;t=fff0c0b4-c9ec-815c-b683-f5628f253d86&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81b39de5d6ed19ddee2e">也有一些denoise model直接产生去除噪声后的图片。</div><div class="notion-text notion-block-fff0c0b4c9ec8173b323d00f67a0eb91">那怎样训练noise predictor呢？怎样获取一张图片中的噪声部分呢？</div><div class="notion-text notion-block-fff0c0b4c9ec815bb77cf9496e6606fe">这里有一个forward process(diffusion process).也就是不断的给原始图像加噪声的过程。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81c9ba55f3bacab4d10f"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fe101b20b-077d-4af4-af85-fbc5b757f2b2%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81c9-ba55-f3bacab4d10f&amp;t=fff0c0b4-c9ec-81c9-ba55-f3bacab4d10f&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81038433c2290f7c6b17">将原始图片一步一步加上噪声的过程就是forward process，将过程中产生的input image和step id作为input，将加入的noise作为ground truth训练noise predictor.</div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec81d891d9e5bc90ba2f52" data-id="fff0c0b4c9ec81d891d9e5bc90ba2f52"><span><div id="fff0c0b4c9ec81d891d9e5bc90ba2f52" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81d891d9e5bc90ba2f52" title="Text-to-Image"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Text-to-Image</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec81baae32f6e9c1d6c9f6">训练文生图模型需要pairs of text-image图片，大型的文生图模型要非常大量的图片。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec818f9dc1e2e2b203d1df"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F36c64cfc-fe38-474d-8c53-4ca7fae39310%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-818f-9dc1-e2e2b203d1df&amp;t=fff0c0b4-c9ec-818f-9dc1-e2e2b203d1df&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81e49b55e4f20eed82c4">LAION包含58.5亿张图片。</div><div class="notion-text notion-block-fff0c0b4c9ec81cc81a0d75b2200378c">到现在也没有用上text，那么怎样利用diffusion model文生图呢？</div><div class="notion-text notion-block-fff0c0b4c9ec812f87eaddb76f00ece5">在denoise model中加入额外的text信息。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8112b965f7e4293dc66f"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fa47324f6-7baa-461f-88a8-99279fd6412b%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8112-b965-f7e4293dc66f&amp;t=fff0c0b4-c9ec-8112-b965-f7e4293dc66f&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec814fa9bcd656e8f002e3">也就是直接把text输入到noise predictor.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8150a959c701ca67a8c9"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F7db4b71e-05c1-4400-8590-a1c7d15cdb5b%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8150-a959-c701ca67a8c9&amp;t=fff0c0b4-c9ec-8150-a959-c701ca67a8c9&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h3 class="notion-h notion-h2 notion-h-indent-0 notion-block-fff0c0b4c9ec81b3960bc2b9f12c384b" data-id="fff0c0b4c9ec81b3960bc2b9f12c384b"><span><div id="fff0c0b4c9ec81b3960bc2b9f12c384b" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec81b3960bc2b9f12c384b" title="Stable Diffusion/DALLE/Imagen 共同的套路"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Stable Diffusion/DALLE/Imagen 共同的套路</span></span></h3><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec8172bb51cff6e3e164c9" data-id="fff0c0b4c9ec8172bb51cff6e3e164c9"><span><div id="fff0c0b4c9ec8172bb51cff6e3e164c9" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec8172bb51cff6e3e164c9" title="Framework"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Framework</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec810fa70df1104aef6d9b">现在主流的文生图模型都是下面的结构：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81bea544d4a2068550b4"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F8f3c3f33-7141-496e-83ca-29d705567f5f%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81be-a544-d4a2068550b4&amp;t=fff0c0b4-c9ec-81be-a544-d4a2068550b4&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81f5801de2292ddbff7b">text经过text encoder得到向量表示；噪声和text表征向量一起输入到Generation model得到一个图片的压缩表示，最后输入到decoder得到图片。</div><div class="notion-text notion-block-fff0c0b4c9ec81f5adbed4b5caeea0c2">Stable Diffusion/DALLE/Imagen采用的都是类似的结构。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec810f8d95df8402857567"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F4a61c8b9-30ff-4710-8e86-d605cf0b5f92%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-810f-8d95-df8402857567&amp;t=fff0c0b4-c9ec-810f-8d95-df8402857567&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec811eacf1c17634aa2bfe"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F349c4981-8f6d-41d4-bb3e-d08ce5217bd5%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-811e-acf1-c17634aa2bfe&amp;t=fff0c0b4-c9ec-811e-acf1-c17634aa2bfe&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8144bc2ce5fc44b3dc06"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Febc2cb50-f514-4a14-b72f-a4fbe4498513%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8144-bc2c-e5fc44b3dc06&amp;t=fff0c0b4-c9ec-8144-bc2c-e5fc44b3dc06&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81af9a58c3efeb0a6be7">下面介绍framework的三个部件。</div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec8117aacac5c37e85d98c" data-id="fff0c0b4c9ec8117aacac5c37e85d98c"><span><div id="fff0c0b4c9ec8117aacac5c37e85d98c" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec8117aacac5c37e85d98c" title="Text Encoder"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Text Encoder</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec81878c2ed526a286c585">可以使用GPT Bert等作为文本编码模型。</div><div class="notion-text notion-block-fff0c0b4c9ec818bbac6cc6d753703da">text encoder对于生成图片的质量非常重要。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec811ea928ec668953c58e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Faf8b64bd-dc19-4f36-9de1-90c1487255b6%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-811e-a928-ec668953c58e&amp;t=fff0c0b4-c9ec-811e-a928-ec668953c58e&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81a6a8c2c09dfe90b9d0">上图中越往右下角表示效果越好，可见encoder size对于模型效果影响较大，而diffusion model的size影响较小。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81c9bd27cd61e4510f8d"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F2675e0db-8aa5-427f-a9c5-8ea5aba428b0%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81c9-bd27-cd61e4510f8d&amp;t=fff0c0b4-c9ec-81c9-bd27-cd61e4510f8d&amp;width=520&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec811d8288dc9d57dc776e">上图中FID是指将图像输入到一个CNN之后得到的分布之间的距离。这里假设generative和real的分布均为高斯分布。所以FID越小表示生成的效果越好。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec812884dbc68ef974b8a4"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fbaf6afff-9d8b-4d08-94d7-2b83313fa736%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8128-84db-c68ef974b8a4&amp;t=fff0c0b4-c9ec-8128-84db-c68ef974b8a4&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81929107fb59969ccbc8">CLIP指标计算文本和图像之间的相似程度。训练时将标注好的image-text pairs输入到模型中，让训练集中成对描述之间距离小，否则距离大。那么在计算CLIP Score时，如果输入的文本和图片很接近，说明score大。所以CLIP Score越大越好。</div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec814e9f3be2ef5656e813" data-id="fff0c0b4c9ec814e9f3be2ef5656e813"><span><div id="fff0c0b4c9ec814e9f3be2ef5656e813" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec814e9f3be2ef5656e813" title="Decoder"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Decoder</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec8186a53cc31d2d13a63f">decoder训练不需要大量的text-image pairs, 训练时只需要图片。</div><div class="notion-text notion-block-fff0c0b4c9ec81b4b8b1cef4b51877fc">但是训练decoder需要中间产物(latent representation)作为输入，所以我们需要一个auto-encoder.输入图片得到图片的latent representation.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81c1b18ac560b6d8dc5f"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F1a737ad9-ab59-4ec6-843f-76131319d3b8%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81c1-b18a-c560b6d8dc5f&amp;t=fff0c0b4-c9ec-81c1-b18a-c560b6d8dc5f&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-fff0c0b4c9ec8142928fff8612316817" data-id="fff0c0b4c9ec8142928fff8612316817"><span><div id="fff0c0b4c9ec8142928fff8612316817" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec8142928fff8612316817" title="Generative Model"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Generative Model</span></span></h4><div class="notion-text notion-block-fff0c0b4c9ec8150bfcdc0d6fad86d58">这个model和上面diffusion model不一样的地方在于这里输入的图片都是latent representation.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81d18df5c4adec17100e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fbf2b2eb7-ac4c-4cbc-a2ef-94404d01971c%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81d1-8df5-c4adec17100e&amp;t=fff0c0b4-c9ec-81d1-8df5-c4adec17100e&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81359edcfc5f1cdedfd1">首先将图片输入到一个encoder中得到latent representation，然后经过diffusion process一步步得到噪声图。</div><div class="notion-text notion-block-fff0c0b4c9ec8126bd58e392e77118c2">将diffusion process的结果作为训练数据训练noise predictor.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81a3b94bc9db9100c9dc"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fcecb8043-fcc3-470e-854a-96d2fcb13af7%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81a3-b94b-c9db9100c9dc&amp;t=fff0c0b4-c9ec-81a3-b94b-c9db9100c9dc&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec813c87bff74e194e904c">在最后通过reverse process产生图片。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8115a90eccfbdeb5909e"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fb90a24e7-22ac-42d3-aef1-2061c5550f35%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8115-a90e-ccfbdeb5909e&amp;t=fff0c0b4-c9ec-8115-a90e-ccfbdeb5909e&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><h3 class="notion-h notion-h2 notion-h-indent-0 notion-block-fff0c0b4c9ec816ea326c5ff71dcb06b" data-id="fff0c0b4c9ec816ea326c5ff71dcb06b"><span><div id="fff0c0b4c9ec816ea326c5ff71dcb06b" class="notion-header-anchor"></div><a class="notion-hash-link" href="#fff0c0b4c9ec816ea326c5ff71dcb06b" title="Diffusion Model数学原理"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title">Diffusion Model数学原理</span></span></h3><div class="notion-text notion-block-fff0c0b4c9ec81258191f41002aaa6a3">实际上在DDPM的原始论文里，Diffusion model的训练过程和上面讲到的原理部分还是有些不同的。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec818badfbfbd85a0f56ee"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fe6e687de-c6bf-47cc-99f1-9fd36df9b91f%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-818b-adfb-fbd85a0f56ee&amp;t=fff0c0b4-c9ec-818b-adfb-fbd85a0f56ee&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec8166b364e8cc695e2916">上图为训练的流程图：</div><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec81d48426d9496c0ba6c2"><li>首先我们需要从原始的clean image分布中采样一张clean image出来，记为<!-- -->;</li></ul><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec815eb02bf45317cc1ff5"><li>然后从1~T中取一个值t;</li></ul><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec81549cb5cdee55c9e098"><li>然后从标准正态分布中采样出噪声ε;</li></ul><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec81f7a3d6f48ba92edbc6"><li>对于公式<!-- -->求梯度，即最小化该公式。</li><ul class="notion-list notion-list-disc notion-block-fff0c0b4c9ec81f7a3d6f48ba92edbc6"><li>公式中后半部分<!-- -->实际上就是noise predictor，他接受两个输入，分别是noisy image和t；</li><li>，<!-- -->，···，<!-- -->都是提前给出的数字。T越大，<!-- -->越小，所以原图<!-- -->比例越小，noise 比例越大。</li><li>所以综上，上述公式就是让noise predictor产生的预测noise越接近真实noise越好。</li></ul></ul><div class="notion-text notion-block-fff0c0b4c9ec8191862ddb5adb9990bf">下图更加直观的展示了训练过程。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec8199b046d367bac353a2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2Fbc16dd44-fc36-4868-ae2d-4654e4f890d1%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8199-b046-d367bac353a2&amp;t=fff0c0b4-c9ec-8199-b046-d367bac353a2&amp;width=519.9921875&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81418046ce2314e4bbd7">所以实际上我们之前预想的DDPM的训练过程和实际上的流程是不太一样的：</div><div class="notion-text notion-block-fff0c0b4c9ec8125a957f6594f51b795">我们一开始认为noise是一步一步被加上的，但是noise实际上是一次被加上。</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81a09f32d2674a0d461d"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F2aa38077-64d6-44ad-b0b6-2150da971990%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-81a0-9f32-d2674a0d461d&amp;t=fff0c0b4-c9ec-81a0-9f32-d2674a0d461d&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81fc9549d0cb22c1b79c">下面再来看一下inference的步骤：</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-fff0c0b4c9ec81758ab8ee78f8c8a565"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:100%;max-width:100%;flex-direction:column;height:100%"><img style="object-fit:cover" src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe86941ae-3a6f-453b-b9e8-0a7f1f519ea0%2F26f90632-e4db-4cd2-9356-69d6719c387b%2FUntitled.png?table=block&amp;id=fff0c0b4-c9ec-8175-8ab8-ee78f8c8a565&amp;t=fff0c0b4-c9ec-8175-8ab8-ee78f8c8a565&amp;width=519.984375&amp;cache=v2" alt="notion image" loading="lazy" decoding="async"/></div></figure><div class="notion-text notion-block-fff0c0b4c9ec81fb9294e26af6bdc79b">上面的流程图很好的展示了这个过程，但是会有一点让人不解的地方在于为什么在最后还要加上一个noise z???</div><div class="notion-text notion-block-fff0c0b4c9ec81d39b5eead2a0abcac1">这一部分DDPM论文中并没有给出解释，李宏毅老师的课程中给出了比较合理的解释，我们在得到一个目标distribution后往往不能取均值，其中一个原因是如果每次都取均值，那么我们模型每次生成的结果都是一样的，例如文生图和语言模型，模型缺乏泛化性；另外一个原因是我们人类在正常产生文本时并不是每一步都采用的是概率最大的结果，所以模型需要从分布中采样，而不是直接取概率最大的均值。一个非常实际的应用就是tacotron模型在inference时也使用了dropout，增加随机性。
另外，diffusion model实际上是一个auto-regressive运用到non-autoregressive的实例，diffusion process实际上可以采用一步实现。在这之前也有一些结合autoregressive和non-autoregressive的方法，Mask-predict就是先利用non-autoregressive产生结果，再mask掉结果中概率小的部分，重新生成结果，一步一步得到最终结果。这样的方法比autoregressive时间复杂度小，但是比non-autoregressive效果好，这可能是未来研究的一个比较好的方向。</div><div class="notion-blank notion-block-fff0c0b4c9ec8153874fd2730709f1ac"> </div></main></div>]]></content>
    </entry>
</feed>